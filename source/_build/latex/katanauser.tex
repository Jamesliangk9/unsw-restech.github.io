%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]


\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



\title{Katana User Documentation}
\date{Jul 01, 2020}
\release{1.0}
\author{Lachlan Simpson}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


This document is available in \sphinxcode{\sphinxupquote{pdf format}} for offline reading.


\chapter{Help and Support}
\label{\detokenize{help_and_support:help-and-support}}\label{\detokenize{help_and_support:id1}}\label{\detokenize{help_and_support::doc}}

\section{Scheduled Maintenance}
\label{\detokenize{help_and_support:scheduled-maintenance}}
\begin{sphinxadmonition}{attention}{Attention:}
There is no maintenance scheduled for the moment.
\end{sphinxadmonition}


\section{Contact the Research Technology Services team}
\label{\detokenize{help_and_support:contact-the-research-technology-services-team}}\label{\detokenize{help_and_support:contact-us}}
Katana issues including: functional issues, software installation, reference data sets, general questions:
Email the \sphinxhref{mailto:ITServiceCentre@unsw.edu.au}{IT Service Centre}, including the word \sphinxstylestrong{Katana} in the subject line.

\begin{sphinxadmonition}{note}{Note:}
This is the best and primary way to get help from UNSW Research Technology Services beyond this document.

When writing your email, please include a clear and detailed description of the issue experienced, including error messages and node name. Something like “It doesn’t work” doesn’t help us help you! If at all possible, include the steps someone else needs to do to reproduce the problem, the job identifier, the date and time of your problem and on which Katana node it occurred, the script filename and the directory you were running from.
\begin{description}
\item[{\sphinxstylestrong{Example of a bad request}}] \leavevmode
i’m trying to do some work on katana, but it seems that the server is slow or not responsive at times. i’m logged in from inside unsw today, so working from home shouldn’t be the issue.

\item[{\sphinxstylestrong{Example of a great request}}] \leavevmode
When I tried to run Sentaurus TCAD today (2020\sphinxhyphen{}05\sphinxhyphen{}01) on Katana I got this error message regardless of structures I wanted to simulate:

“Job failed
Error: Child process with pid ‘116643’ got the signal ‘SIGSEGV’ (segmentation violation)
gjob exits with status 1”

My job ran on k052 with jobid 300000, my zid is z2134567

\end{description}
\end{sphinxadmonition}

For face to face support: \sphinxhref{https://research.unsw.edu.au/hacky-hour}{Hacky Hour} Thursdays, 3pm.

For questions about \sphinxhref{https://research.unsw.edu.au/research-data-management-unsw}{research data at UNSW} on storage, movement or Data Management Plans, please
email the \sphinxhref{mailto:rdm@unsw.edu.au}{Research Data Team}


\section{Katana System Status and Known Issues}
\label{\detokenize{help_and_support:katana-system-status-and-known-issues}}
No known issues at the moment.


\section{Katana Terms of Use}
\label{\detokenize{help_and_support:katana-terms-of-use}}
Any use of Katana is covered by the \sphinxhref{https://www.it.unsw.edu.au/students/policies/agree\_to\_rules.html}{Conditions of Use \sphinxhyphen{} UNSW ICT Resources}.

\begin{sphinxadmonition}{important}{Important:}
Katana is not suitable for highly sensitive data. You should use the UNSW Data Classification scheme to classify your data and learn about managing your research data by visiting the \sphinxhref{https://research.unsw.edu.au/research-data-management-hub}{Research Data Management Hub}.
\end{sphinxadmonition}


\chapter{Using Katana}
\label{\detokenize{using_katana/index:using-katana}}\label{\detokenize{using_katana/index:katana}}\label{\detokenize{using_katana/index::doc}}

\section{About Katana}
\label{\detokenize{using_katana/about_katana:about-katana}}\label{\detokenize{using_katana/about_katana:id1}}\label{\detokenize{using_katana/about_katana::doc}}
Katana is a shared computational cluster located on campus at UNSW that has been designed to provide easy access to computational resources. With over 4000 CPU cores spread over a large number of compute nodes each with up to 1Tb of memory, Katana provides a flexible compute environment where users can run jobs that wouldn’t be possible or practical on a desktop or laptop.

Katana is powerful on it’s own, but can be seen as a training or development base before migrating up to systems like as Australia’s peak HPC system \sphinxhref{https://nci.org.au/our-systems/hpc-systems}{Gadi}, located at \sphinxhref{https://nci.org.au/}{NCI}. Research Technology Services also provide training, advice and support for new users or those uncertain if High Performance Computing is the right fit for their research needs.


\subsection{System Configuration}
\label{\detokenize{using_katana/about_katana:system-configuration}}\label{\detokenize{using_katana/about_katana:id2}}\begin{itemize}
\item {} 
RPM based Linux OSes. RedHat on the management plane, CentOS on the nodes

\item {} 
\sphinxhref{https://www.pbspro.org/}{PBSPro} version 19.1.3

\item {} 
Large global scratch at \sphinxcode{\sphinxupquote{/srv/scratch}}, local scratch at \sphinxcode{\sphinxupquote{\$TMPDIR}}

\item {} 
12, 48, 100, 200 hour {\hyperref[\detokenize{glossary:term-Walltime}]{\sphinxtermref{\DUrole{xref,std,std-term}{Walltime}}}} queues with prioritisation

\end{itemize}


\subsection{Compute}
\label{\detokenize{using_katana/about_katana:compute}}\label{\detokenize{using_katana/about_katana:compute-resources}}\begin{itemize}
\item {} 
Hetergenous hardware: Dell, Lenovo, Huawei.

\item {} 
roughly 170 nodes

\end{itemize}


\subsection{GPU Compute}
\label{\detokenize{using_katana/about_katana:gpu-compute}}\label{\detokenize{using_katana/about_katana:gpu-resources}}
The most popular use of these nodes is for Tensorflow.
\begin{itemize}
\item {} 
four GPU capable nodes, Tesla V100\sphinxhyphen{}SXM2, 32GB

\item {} 
three are dedicated for the department that owns them

\item {} 
one is general use for all researchers

\end{itemize}


\section{Accessing Katana}
\label{\detokenize{using_katana/accessing_katana:accessing-katana}}\label{\detokenize{using_katana/accessing_katana::doc}}
Anyone at UNSW can apply for a general account on Katana. This level is designed for those that think Katana would suit their research needs or will typically use less than 10,000 CPU hours a quarter. This level still gets access to the same level of support including software installation, help getting started or running their jobs. The only difference is the number of compute jobs that can be run at any time and how long they can run for \sphinxhyphen{} general users can only use a 12 hour {\hyperref[\detokenize{glossary:term-Walltime}]{\sphinxtermref{\DUrole{xref,std,std-term}{Walltime}}}}.

If your needs require more CPU hours or consulation, some Faculties, Schools and Research Groups have invested in Katana and have a higher level of access. Users in this situation should speak to their supervisor.


\subsection{Requesting an Account}
\label{\detokenize{using_katana/accessing_katana:requesting-an-account}}\label{\detokenize{using_katana/accessing_katana:id1}}
To apply for an account you can send an email to the \sphinxhref{mailto:ITServiceCentre@unsw.edu.au}{UNSW IT Service Centre} giving your zID, your role within UNSW and the name of your supervisor or head of your research group.


\subsection{Connecting to Katana}
\label{\detokenize{using_katana/accessing_katana:connecting-to-katana}}\label{\detokenize{using_katana/accessing_katana:id2}}
\begin{sphinxadmonition}{note}{Note:}
When you are connecting to Katana via \sphinxcode{\sphinxupquote{katana.restech.unsw.edu.au}} you are connecting to one of two login nodes \sphinxcode{\sphinxupquote{katana1.restech.unsw.edu.au}} or \sphinxcode{\sphinxupquote{katana2.restech.unsw.edu.au}}. If you have a long running {\hyperref[\detokenize{software/tmux:tmux}]{\sphinxcrossref{\DUrole{std,std-ref}{TMUX}}}} open, you will need to login to the node on which it was started.
\end{sphinxadmonition}


\subsubsection{Linux and Mac}
\label{\detokenize{using_katana/accessing_katana:linux-and-mac}}
From a Linux or Mac OS machine you can connect via ssh in a terminal:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
laptop:\PYGZti{}\PYGZdl{} ssh z1234567@katana.restech.unsw.edu.au
\end{sphinxVerbatim}


\subsubsection{Windows}
\label{\detokenize{using_katana/accessing_katana:windows}}
From a Windows machine a SSH client such as \sphinxhref{https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html}{PuTTY} or \sphinxhref{https://mobaxterm.mobatek.net/}{MobaXTerm} is required.


\subsubsection{Graphical sessions}
\label{\detokenize{using_katana/accessing_katana:graphical-sessions}}\label{\detokenize{using_katana/accessing_katana:graphical-session}}
Some software \sphinxhyphen{} \sphinxstylestrong{Ansys}, {\hyperref[\detokenize{software/python-jupyter-notebooks:jupyter-notebooks}]{\sphinxcrossref{\DUrole{std,std-ref}{Jupyter Notebooks}}}}, \sphinxstylestrong{Matlab}, and {\hyperref[\detokenize{software/r:r-and-rstudio}]{\sphinxcrossref{\DUrole{std,std-ref}{R and RStudio}}}} being among the most popular \sphinxhyphen{} are easier with a graphical session. If you require an interactive graphical session to Katana then you can use the \sphinxhref{http://wiki.x2go.org/doku.php}{X2Go} client.

Start X2Go and create a session for Katana. The details that you need to enter for the session are:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Session name: Katana
Host: katana.restech.unsw.edu.au
Login: zID
Session type: Mate
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{x2go}.png}

\begin{sphinxadmonition}{warning}{Warning:}
The usability of a graphical connection to Katana is highly dependent on network latency and performance.
\end{sphinxadmonition}

Once you have logged into a Katana desktop, you should start a terminal

\noindent\sphinxincludegraphics{{terminal_graphical_session}.png}

Then run an interactive session. Here you can see a command similar to what you would run for an interactive session with 8 CPUs and 16 GB for one hour. You will probably need more time. You can tell your interactive session has started when you see the name of the machine change \sphinxhyphen{} in this image I am on k247.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
qsub \PYGZhy{}I \PYGZhy{}X \PYGZhy{}l \PYG{k}{select}\PYG{o}{=}\PYG{l+m}{1}:ncpus\PYG{o}{=}\PYG{l+m}{8}:mem\PYG{o}{=}16gb,walltime\PYG{o}{=}\PYG{l+m}{1}:00:00
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{interactive_session_graphical}.png}

Once that’s started, you can load the modules and run the command line name of the software you want. That is how you run Graphical Interfaces or GUIs using Katana’s grunt.

\noindent\sphinxincludegraphics{{rstudio_graphical_session}.png}


\section{Running Jobs on Katana}
\label{\detokenize{using_katana/running_jobs:running-jobs-on-katana}}\label{\detokenize{using_katana/running_jobs:running-jobs}}\label{\detokenize{using_katana/running_jobs::doc}}

\subsection{Brief Overview}
\label{\detokenize{using_katana/running_jobs:brief-overview}}
The {\hyperref[\detokenize{glossary:term-Login-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Login Node}}}} of a cluster is a shared resource for all users and is used for preparing, submitting and managing jobs. Never run any computationally intensive processes on the login nodes. Jobs are submitted from the login node, which delivers them to the {\hyperref[\detokenize{glossary:term-Head-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Head Node}}}} for job and resource management. Once the resources have been allocated and are available, the job will run on one or more of the compute nodes as requested.

Different clusters use different tools to manage resources and schedule jobs \sphinxhyphen{} \sphinxhref{https://www.pbspro.org/}{OpenPBS} and \sphinxhref{https://slurm.schedmd.com/}{SLURM} are two popular systems. Katana, like NCI’s Gadi, uses \sphinxhref{https://www.pbspro.org/}{OpenPBS} for this purpose.

Jobs are submitted using the \sphinxcode{\sphinxupquote{qsub}} command. There are two types of job that \sphinxcode{\sphinxupquote{qsub}} will accept: an {\hyperref[\detokenize{glossary:term-Interactive-Job}]{\sphinxtermref{\DUrole{xref,std,std-term}{Interactive Job}}}} and a {\hyperref[\detokenize{glossary:term-Batch-Job}]{\sphinxtermref{\DUrole{xref,std,std-term}{Batch Job}}}}. Regardless of type, the resource manager will put your job in a {\hyperref[\detokenize{glossary:term-Queue}]{\sphinxtermref{\DUrole{xref,std,std-term}{Queue}}}}.

An \sphinxstylestrong{interactive job} provides a shell session on a {\hyperref[\detokenize{glossary:term-Compute-Nodes}]{\sphinxtermref{\DUrole{xref,std,std-term}{Compute Nodes}}}}. You interact directly with the compute node running the software you need explicitly. Interactive jobs are useful for experimentation, debugging, and planning for \sphinxstylestrong{batch jobs}.

In contrast, a {\hyperref[\detokenize{glossary:term-Batch-Job}]{\sphinxtermref{\DUrole{xref,std,std-term}{Batch Job}}}} is a scripted job that \sphinxhyphen{} after submission via \sphinxcode{\sphinxupquote{qsub}} \sphinxhyphen{} runs from start to finish without any user intervention. The vast majority of jobs on the cluster are batch jobs. This type of job is appropriate for production runs that will consume several hours or days.

To submit a {\hyperref[\detokenize{glossary:term-Batch-Job}]{\sphinxtermref{\DUrole{xref,std,std-term}{Batch Job}}}} you will need to create a job script which specifies the resources that your job requires and calls your program. The general structure of {\hyperref[\detokenize{using_katana/running_jobs:a-job-script}]{\sphinxcrossref{A Job Script}}} is shown below.

\begin{sphinxadmonition}{important}{Important:}
All jobs go into a {\hyperref[\detokenize{glossary:term-Queue}]{\sphinxtermref{\DUrole{xref,std,std-term}{Queue}}}} while waiting for resources to become available. The length of time your jobs wait in a queue for resources depends on a number of factors.
\end{sphinxadmonition}

The main resources available for use are Memory (RAM), {\hyperref[\detokenize{glossary:term-CPU-Core}]{\sphinxtermref{\DUrole{xref,std,std-term}{CPU Core}}}} (number of CPUs) and {\hyperref[\detokenize{glossary:term-Walltime}]{\sphinxtermref{\DUrole{xref,std,std-term}{Walltime}}}} (how long you want the CPUs for). These need to be considered carefully when writing your job script, since the decisions you make will impact which queue your jobs ends up on.

As you request more memory, the number of available queues goes down. The memory limits, in GB, at which the number of queues decreases are 124, 180, 248, 370, 750 and 1000.

Similarly, when considering the number of CPU cores, the available resources reduce at 16, 20, 24, 28, 32, 44 and 64 CPU cores.

Walltime provides the biggest constraint on your submitted jobs. The points at which resource availability is reduced are 12, 48, 100 and 200 hours

Jobs have the following restrictions:
\begin{itemize}
\item {} 
Jobs of up to 12 hours can run anywhere on the cluster

\item {} 
Jobs of up to 100 hours can run on nodes belonging to your group and the general nodes

\item {} 
Jobs of up to 200 hours can only run on nodes belonging to your group

\end{itemize}


\subsection{Interactive Jobs}
\label{\detokenize{using_katana/running_jobs:interactive-jobs}}\label{\detokenize{using_katana/running_jobs:interactive-session}}\label{\detokenize{using_katana/running_jobs:interactive-job}}
An interactive job or interactive session is a session on a compute node with the required physical resources for the period of time requested. To request an interactive job, add the \sphinxhyphen{}I flag (capital i) to \sphinxcode{\sphinxupquote{qsub}}. Default sessions will have 1 CPU core, 1GB and 1 hour

For example, the following two commands. The first provides a default session, the second provides a session with two CPU core and 8GB memory for three hours. You can tell when an interactive job has started when you see the name of the server change from \sphinxcode{\sphinxupquote{katana1}} or \sphinxcode{\sphinxupquote{katana2}} to the name of the server your job is running on. In these cases it’s \sphinxcode{\sphinxupquote{k181}} and \sphinxcode{\sphinxupquote{k201}} respectively.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} qsub \PYGZhy{}I
qsub: waiting \PYG{k}{for} job \PYG{l+m}{313704}.kman.restech.unsw.edu.au to start
qsub: job \PYG{l+m}{313704}.kman.restech.unsw.edu.au ready
\PYG{o}{[}z1234567@k181 \PYGZti{}\PYG{o}{]}\PYGZdl{}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} qsub \PYGZhy{}I \PYGZhy{}l \PYG{k}{select}\PYG{o}{=}\PYG{l+m}{1}:ncpus\PYG{o}{=}\PYG{l+m}{2}:mem\PYG{o}{=}8gb,walltime\PYG{o}{=}\PYG{l+m}{3}:00:00
qsub: waiting \PYG{k}{for} job \PYG{l+m}{1234}.kman.restech.unsw.edu.au to start
qsub: job \PYG{l+m}{1234}.kman.restech.unsw.edu.au ready
\PYG{o}{[}z1234567@k201 \PYGZti{}\PYG{o}{]}\PYGZdl{}
\end{sphinxVerbatim}

Jobs are constrained by the resources that are requested. In the previous example the first job \sphinxhyphen{} running on \sphinxcode{\sphinxupquote{k181}} \sphinxhyphen{} would be terminated after 1 hour or if a command within the session consumed more than 8GB memory. The job (and therefore the session) can also be terminated by the user with \sphinxcode{\sphinxupquote{CTRL\sphinxhyphen{}D}} or the \sphinxcode{\sphinxupquote{logout}} command.

Interactive jobs can be particularly useful while developing and testing code for a future batch job, or performing an interactive analysis that requires significant compute resources. Never attempt such tasks on the login node – submit an interactive job instead.


\subsection{Batch Jobs}
\label{\detokenize{using_katana/running_jobs:batch-jobs}}\label{\detokenize{using_katana/running_jobs:id1}}
A batch job is a script that runs autonomously on a compute node. The script must contain the necessary sequence of commands to complete a task independently of any input from the user. This section contains information about how to create and submit a batch job on Katana.


\subsubsection{Getting Started}
\label{\detokenize{using_katana/running_jobs:getting-started}}
The following script simply executes a pre\sphinxhyphen{}compiled program (“myprogram”) in the user’s home directory:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/bin/bash}

\PYG{n+nb}{cd} \PYG{n+nv}{\PYGZdl{}HOME}

./myprogram
\end{sphinxVerbatim}

This script can be submitted to the cluster with \sphinxcode{\sphinxupquote{qsub}} and it will become a job and be assigned to a queue. If the script is in a file called \sphinxcode{\sphinxupquote{myjob.pbs}} then the following command will submit the job with the default resource requirements (1 CPU core with 1GB of memory for 1 hour):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} qsub myjob.pbs
\PYG{l+m}{1237}.kman.restech.unsw.edu.au
\end{sphinxVerbatim}

As with interactive jobs, the \sphinxcode{\sphinxupquote{\sphinxhyphen{}l}} (lowercase L) flag can be used to specify resource requirements for the job:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana \PYGZti{}\PYG{o}{]}\PYGZdl{} qsub \PYGZhy{}l \PYG{k}{select}\PYG{o}{=}\PYG{l+m}{1}:ncpus\PYG{o}{=}\PYG{l+m}{1}:mem\PYG{o}{=}4gb,walltime\PYG{o}{=}\PYG{l+m}{12}:00:00 myjob.pbs
\PYG{l+m}{1238}.kman.restech.unsw.edu.au
\end{sphinxVerbatim}


\subsubsection{A Job Script}
\label{\detokenize{using_katana/running_jobs:a-job-script}}
Job scripts offer a much more convenient method for invoking any of the options that can be passed to \sphinxcode{\sphinxupquote{qsub}} on the command\sphinxhyphen{}line. In a shell script, a line starting with \# is a comment and will be ignored by the shell interpreter. However, in a job script, a line starting with \#PBS can be used to pass options to the \sphinxcode{\sphinxupquote{qsub}} command.

Here is an overview of the different parts of a job script which we will examine further below. In the following sections we will add some code, explain what it does, then show some new code, and iterate up to something quite powerful.

For the previous example, the job script could be rewritten as:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/bin/bash}

\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l select=1:ncpus=1:mem=4gb}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l walltime=12:00:00}

\PYG{n+nb}{cd} \PYG{n+nv}{\PYGZdl{}HOME}

./myprogram
\end{sphinxVerbatim}

This structure is the most common that you will use. The top line must be \sphinxcode{\sphinxupquote{\#!/bin/bash}} \sphinxhyphen{} we are running bash scripts, and this is required.
The following section \sphinxhyphen{} the lines starting with \sphinxcode{\sphinxupquote{\#PBS}} \sphinxhyphen{} are where we will be configuring how the job will be run \sphinxhyphen{} here we are asking for resources.
The final section shows the commands that will be executed in the configured session.

The script can now be submitted with much less typing:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana \PYGZti{}\PYG{o}{]}\PYGZdl{} qsub myjob.pbs
\PYG{l+m}{1239}.kman.restech.unsw.edu.au
\end{sphinxVerbatim}

Unlike submission of an interactive job, which results in a session on a compute node ready to accept commands, the submission of a batch job returns the ID of the new job. This is confirmation that the job was submitted successfully. The job is now processed by the job scheduler and resource manager. Commands for checking the status of the job can be found in the section {\hyperref[\detokenize{using_katana/running_jobs:managing-jobs-on-katana}]{\sphinxcrossref{\DUrole{std,std-ref}{Managing Jobs on Katana}}}}.

If you wish to be notified by email when the job finishes then use the \sphinxcode{\sphinxupquote{\sphinxhyphen{}M}} flag to specify the email address and the \sphinxcode{\sphinxupquote{\sphinxhyphen{}m}} flag to declare which events cause a notification. Here we will get an email if the job aborts (\sphinxcode{\sphinxupquote{\sphinxhyphen{}m a}}) due to an error or ends (\sphinxcode{\sphinxupquote{\sphinxhyphen{}m e}}) naturally.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}M your.name.here@unsw.edu.au}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}m ae}
\end{sphinxVerbatim}

The output that would normally go to screen and error messages of a batch job will be saved to file when your job ends. By default these files will be called \sphinxcode{\sphinxupquote{JOB\_NAME.oJOB\_ID}} and \sphinxcode{\sphinxupquote{JOB\_NAME.eJOB\_ID}}, and they will appear in the directory that was the current working directory when the job was submitted. In the above example, they would be \sphinxcode{\sphinxupquote{myjob.o1239}} and \sphinxcode{\sphinxupquote{myjob.e1239}}.  You can merge these into a single file with the \sphinxcode{\sphinxupquote{\sphinxhyphen{}j oe}} flag. The \sphinxcode{\sphinxupquote{\sphinxhyphen{}o}} flag allows you to rename the file.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}j oe}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}o /home/z1234567/results/Output\PYGZus{}Report}
\end{sphinxVerbatim}

When a job starts, it needs to know where to save it’s output and do it’s work. This is called the \sphinxstyleemphasis{current working directory}. By default the job scheduler will make your \sphinxstyleemphasis{current working directory} your home directory (\sphinxcode{\sphinxupquote{/home/z1234567}}). This isn’t likely or ideal and is important that each job sets its current working directory appropriately. There are a couple of ways to do this, the easiest is to set the \sphinxstyleemphasis{current working directory} to the directory you are in when you execute \sphinxcode{\sphinxupquote{qsub}} by using

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{cd} \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}WORKDIR}
\end{sphinxVerbatim}

There is one last special variable you should know about, especially if you are working with large datasets. The storage on the compute node your job is running on will always be faster than the network drive.

If you use the storage close to the CPUs \sphinxhyphen{} in the server rather than on the shared drives, called {\hyperref[\detokenize{glossary:term-Local-Scratch}]{\sphinxtermref{\DUrole{xref,std,std-term}{Local Scratch}}}} \sphinxhyphen{} you can often save hours of time reading and writing across the network.

In order to do this, you can copy data to and from the local scratch, called \sphinxcode{\sphinxupquote{\$TMPDIR}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
cp /home/z1234567/project/massivedata.tar.gz \PYG{n+nv}{\PYGZdl{}TMPDIR}
tar xvf massivedata.tar.gz
my\PYGZus{}analysis.py massive\PYGZus{}data
cp \PYGZhy{}r \PYG{n+nv}{\PYGZdl{}TMPDIR}/my\PYGZus{}output /home/z1234567
\end{sphinxVerbatim}

There are a lot of things that can be done with PBSPro, but you don’t and won’t need to know it all. These few basics will get you started.

Here’s the full script as we’ve described. You can copy this into a text editor and once you’ve changed our dummy values for yours, you only need to change the last line.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/bin/bash}

\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l select=1:ncpus=1:mem=4gb}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l walltime=12:00:00}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}M your.name.here@unsw.edu.au}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}m ae}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}j oe}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}o /home/z1234567/results/Output\PYGZus{}Report}

\PYG{n+nb}{cd} \PYG{n+nv}{\PYGZdl{}PBS\PYGZus{}O\PYGZus{}WORKDIR}

./myprogram
\end{sphinxVerbatim}


\subsection{Array Jobs}
\label{\detokenize{using_katana/running_jobs:array-jobs}}\label{\detokenize{using_katana/running_jobs:id2}}
One common use of computational clusters is to do the same thing multiple times \sphinxhyphen{} sometimes with slightly different input, sometimes to get averages from randomness within the process. This is made easier with array jobs.

An array job is a single job script that spawns many almost identical sub\sphinxhyphen{}jobs. The only difference between the sub\sphinxhyphen{}jobs is an environment variable \sphinxcode{\sphinxupquote{\$PBS\_ARRAY\_INDEX}} whose value uniquely identifies an individual sub\sphinxhyphen{}job. A regular job becomes an array job when it uses the \sphinxcode{\sphinxupquote{\#PBS \sphinxhyphen{}J}} flag.

For example, the following script will spawn 100 sub\sphinxhyphen{}jobs. Each sub\sphinxhyphen{}job will require one CPU core, 1GB memory and 1 hour run\sphinxhyphen{}time, and it will execute the same application. However, a different input file will be passed to the application within each sub\sphinxhyphen{}job. The first sub\sphinxhyphen{}job will read input data from a file called \sphinxcode{\sphinxupquote{1.dat}}, the second sub\sphinxhyphen{}job will read input data from a file called \sphinxcode{\sphinxupquote{2.dat}} and so on.

\begin{sphinxadmonition}{note}{Note:}
In this example we are using \sphinxhref{https://www.gnu.org/software/bash/manual/html\_node/Brace-Expansion.html}{brace expansion} \sphinxhyphen{} the \{\} characters around the bash variables \sphinxhyphen{} because they are needed for variables that change, like array indices. They aren’t strictly necessary for \sphinxcode{\sphinxupquote{\$PBS\_O\_WORKDIR}} but we include them to show consistency.
\end{sphinxadmonition}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/bin/bash}

\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l select=1:ncpus=1:mem=1gb}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l walltime=1:00:00}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}j oe}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}J 1\PYGZhy{}100}

\PYG{n+nb}{cd} \PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{PBS\PYGZus{}O\PYGZus{}WORKDIR}\PYG{l+s+si}{\PYGZcb{}}

./myprogram \PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{PBS\PYGZus{}ARRAY\PYGZus{}INDEX}\PYG{l+s+si}{\PYGZcb{}}.dat
\end{sphinxVerbatim}

There are some more examples of array jobs including how to group your computations in an array job on the \sphinxhref{https://github.com/unsw-edu-au/Restech-HPC/tree/master/hpc-examples}{UNSW Github HPC examples} page.


\subsection{Splitting large Batch Jobs}
\label{\detokenize{using_katana/running_jobs:splitting-large-batch-jobs}}
If your batch job can be split into multiple steps you may want to split one big job up into a number of smaller jobs. There are a number of reasons to spend the time to implement this.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
If your large job runs for over 200 hours, it won’t finish on Katana.

\item {} 
If your job has multiple steps which use different amounts of resources at each step. If you have a pipeline that takes 50 hours to run and needs 200GB of memory for an hour, but only 50GB the rest of the time, then the memory is sitting idle.

\item {} 
Katana has prioritisations based on how many resources any one user uses. If you ask for 200GB of memory, this will be accounted for when working out your next job’s priority.

\item {} 
There’s no other way to say this, but because there are more resources for 12 hour jobs, seven or eight 12 hour jobs will often finish well before a single 100 hour job even starts.

\end{enumerate}


\subsection{Get information about the state of the scheduler}
\label{\detokenize{using_katana/running_jobs:get-information-about-the-state-of-the-scheduler}}\label{\detokenize{using_katana/running_jobs:state-of-pbs}}
When deciding which jobs to run, the scheduler takes the following details into account:
\begin{itemize}
\item {} 
are there available resources

\item {} 
how recently has this user run jobs successfully

\item {} 
how many resources has this user used recently

\item {} 
how long is the job’s Walltime

\item {} 
how long has the job been in the queue

\end{itemize}

You can get an overview of the compute nodes and a list of all the jobs running on each node using \sphinxcode{\sphinxupquote{pstat}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 src\PYG{o}{]}\PYGZdl{} pstat
k001  normal\PYGZhy{}mrcbio           free          \PYG{l+m}{12}/44   \PYG{l+m}{200}/1007gb  \PYG{l+m}{314911}*12
k002  normal\PYGZhy{}mrcbio           free          \PYG{l+m}{40}/44    \PYG{l+m}{56}/ 377gb  \PYG{l+m}{314954}*40
k003  normal\PYGZhy{}mrcbio           free          \PYG{l+m}{40}/44   \PYG{l+m}{375}/ 377gb  \PYG{l+m}{314081}*40
k004  normal\PYGZhy{}mrcbio           free          \PYG{l+m}{40}/44    \PYG{l+m}{62}/ 377gb  \PYG{l+m}{314471}*40
k005  normal\PYGZhy{}ccrc             free           \PYG{l+m}{0}/32     \PYG{l+m}{0}/ 187gb
k006  normal\PYGZhy{}physics          job\PYGZhy{}busy      \PYG{l+m}{32}/32   \PYG{l+m}{180}/ 187gb  \PYG{l+m}{282533}*32
k007  normal\PYGZhy{}physics          job\PYGZhy{}busy      \PYG{l+m}{32}/32   \PYG{l+m}{180}/ 187gb  \PYG{l+m}{284666}*32
k008  normal\PYGZhy{}physics          free           \PYG{l+m}{0}/32     \PYG{l+m}{0}/ 187gb
k009  normal\PYGZhy{}physics          job\PYGZhy{}busy      \PYG{l+m}{32}/32   \PYG{l+m}{124}/ 187gb  \PYG{l+m}{314652}*32
k010  normal\PYGZhy{}physics          free           \PYG{l+m}{0}/32     \PYG{l+m}{0}/ 187gb
\end{sphinxVerbatim}

To get information about a particular node, you can use \sphinxcode{\sphinxupquote{pbsnodes}} but on it’s own it is a firehose. Using it with a particular node name is more effective:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 src\PYG{o}{]}\PYGZdl{} pbsnodes k254
k254
     \PYG{n+nv}{Mom} \PYG{o}{=} k254
     \PYG{n+nv}{ntype} \PYG{o}{=} PBS
     \PYG{n+nv}{state} \PYG{o}{=} job\PYGZhy{}busy
     \PYG{n+nv}{pcpus} \PYG{o}{=} \PYG{l+m}{32}
     \PYG{n+nb}{jobs} \PYG{o}{=} \PYG{l+m}{313284}.kman.restech.unsw.edu.au/0, \PYG{l+m}{313284}.kman.restech.unsw.edu.au/1, \PYG{l+m}{313284}.kman.restech.unsw.edu.au/2
     resources\PYGZus{}available.arch \PYG{o}{=} linux
     resources\PYGZus{}available.cpuflags \PYG{o}{=} avx,avx2,avx512bw,avx512cd,avx512dq,avx512f,avx512vl
     resources\PYGZus{}available.cputype \PYG{o}{=} skylake\PYGZhy{}avx512
     resources\PYGZus{}available.host \PYG{o}{=} k254
     resources\PYGZus{}available.mem \PYG{o}{=} 196396032kb
     resources\PYGZus{}available.ncpus \PYG{o}{=} \PYG{l+m}{32}
     resources\PYGZus{}available.node\PYGZus{}weight \PYG{o}{=} \PYG{l+m}{1}
     resources\PYGZus{}available.normal\PYGZhy{}all \PYG{o}{=} Yes
     resources\PYGZus{}available.normal\PYGZhy{}qmchda \PYG{o}{=} Yes
     resources\PYGZus{}available.normal\PYGZhy{}qmchda\PYGZhy{}maths\PYGZus{}business\PYGZhy{}maths \PYG{o}{=} Yes
     resources\PYGZus{}available.normal\PYGZhy{}qmchda\PYGZhy{}maths\PYGZus{}business\PYGZhy{}maths\PYGZhy{}general \PYG{o}{=} Yes
     resources\PYGZus{}available.vmem \PYG{o}{=} 198426624kb
     resources\PYGZus{}available.vnode \PYG{o}{=} k254
     resources\PYGZus{}available.vntype \PYG{o}{=} compute
     resources\PYGZus{}assigned.accelerator\PYGZus{}memory \PYG{o}{=} 0kb
     resources\PYGZus{}assigned.hbmem \PYG{o}{=} 0kb
     resources\PYGZus{}assigned.mem \PYG{o}{=} 50331648kb
     resources\PYGZus{}assigned.naccelerators \PYG{o}{=} \PYG{l+m}{0}
     resources\PYGZus{}assigned.ncpus \PYG{o}{=} \PYG{l+m}{32}
     resources\PYGZus{}assigned.ngpus \PYG{o}{=} \PYG{l+m}{0}
     resources\PYGZus{}assigned.vmem \PYG{o}{=} 0kb
     \PYG{n+nv}{resv\PYGZus{}enable} \PYG{o}{=} True
     \PYG{n+nv}{sharing} \PYG{o}{=} default\PYGZus{}shared
     \PYG{n+nv}{last\PYGZus{}state\PYGZus{}change\PYGZus{}time} \PYG{o}{=} Thu Apr \PYG{l+m}{30} \PYG{l+m}{08}:06:23 \PYG{l+m}{2020}
     \PYG{n+nv}{last\PYGZus{}used\PYGZus{}time} \PYG{o}{=} Thu Apr \PYG{l+m}{30} \PYG{l+m}{07}:08:25 \PYG{l+m}{2020}
\end{sphinxVerbatim}


\subsection{Managing Jobs on Katana}
\label{\detokenize{using_katana/running_jobs:managing-jobs-on-katana}}\label{\detokenize{using_katana/running_jobs:managing-jobs}}
Once you have jobs running, you will want visibility of the system so that you can manage them \sphinxhyphen{} delete jobs, change jobs, check that jobs are still running.

There are a couple of easy to use commands that help with this process.


\subsubsection{qstat}
\label{\detokenize{using_katana/running_jobs:qstat}}

\paragraph{Show all jobs on the system}
\label{\detokenize{using_katana/running_jobs:show-all-jobs-on-the-system}}\label{\detokenize{using_katana/running_jobs:more-info-from-pbs}}
\sphinxcode{\sphinxupquote{qstat}} gives very long output. Consider piping to \sphinxcode{\sphinxupquote{less}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} qstat \PYG{p}{|} less
Job id            Name             User              Time Use S Queue
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}  \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}  \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYG{l+m}{245821}.kman       s\PYGZhy{}m20\PYGZhy{}i20\PYGZhy{}200h   z1234567                 \PYG{l+m}{0} Q medicine200
\PYG{l+m}{280163}.kman       Magcomp25A2      z1234567          \PYG{l+m}{3876}:18: R mech700
\PYG{l+m}{282533}.kman       Proj\PYGZus{}MF\PYGZus{}Nu1      z1234567          \PYG{l+m}{3280}:08: R cosmo200
\PYG{l+m}{284666}.kman       Proj\PYGZus{}BR\PYGZus{}Nu1      z1234567          \PYG{l+m}{3279}:27: R cosmo200
\PYG{l+m}{308559}.kman       JASASec55        z1234567          \PYG{l+m}{191}:21:3 R maths200
\PYG{l+m}{309615}.kman       \PYG{l+m}{2020}\PYGZhy{}04\PYGZhy{}06.BUSC  z1234567          \PYG{l+m}{185}:00:5 R babs200
\PYG{l+m}{310623}.kman       Miaocyclegan     z1234567          \PYG{l+m}{188}:06:3 R simigpu200
...
\end{sphinxVerbatim}


\paragraph{List just my jobs}
\label{\detokenize{using_katana/running_jobs:list-just-my-jobs}}
You can use either your \sphinxstylestrong{ZID} or the {\hyperref[\detokenize{glossary:term-Environment-Variable}]{\sphinxtermref{\DUrole{xref,std,std-term}{Environment Variable}}}} \sphinxcode{\sphinxupquote{\$USER}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z2134567@katana2 src\PYG{o}{]}\PYGZdl{} qstat \PYGZhy{}u \PYG{n+nv}{\PYGZdl{}USER}
kman.restech.unsw.edu.au:
                                                            Req\PYG{l+s+s1}{\PYGZsq{}d  Req\PYGZsq{}}d   Elap
Job ID          Username Queue    Jobname    SessID NDS TSK Memory Time  S Time
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYG{l+m}{315230}.kman.res z2134567 general1 job.pbs       \PYGZhy{}\PYGZhy{}    \PYG{l+m}{1}   \PYG{l+m}{1}    1gb \PYG{l+m}{01}:00 Q   \PYGZhy{}\PYGZhy{}
\end{sphinxVerbatim}

If you add the \sphinxcode{\sphinxupquote{\sphinxhyphen{}s}} flag, you will get slightly more status information.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 src\PYG{o}{]}\PYGZdl{} qstat \PYGZhy{}su z1234567

kman.restech.unsw.edu.au:
                                                            Req\PYG{l+s+s1}{\PYGZsq{}d  Req\PYGZsq{}}d   Elap
Job ID          Username Queue    Jobname    SessID NDS TSK Memory Time  S Time
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYG{l+m}{315230}.kman.res z1234567 general1 job.pbs     \PYG{l+m}{61915}   \PYG{l+m}{1}   \PYG{l+m}{1}    1gb \PYG{l+m}{01}:00 R \PYG{l+m}{00}:03
   Job run at Fri May \PYG{l+m}{01} at \PYG{l+m}{14}:28 on \PYG{o}{(}k019:mem\PYG{o}{=}1048576kb:ncpus\PYG{o}{=}\PYG{l+m}{1}:ngpus\PYG{o}{=}\PYG{l+m}{0}\PYG{o}{)}
\PYG{l+m}{315233}.kman.res z1234567 general1 job.pbs       \PYGZhy{}\PYGZhy{}    \PYG{l+m}{1}   \PYG{l+m}{1}    1gb \PYG{l+m}{01}:00 Q   \PYGZhy{}\PYGZhy{}
    \PYGZhy{}\PYGZhy{}
\end{sphinxVerbatim}


\paragraph{List information about a particular job}
\label{\detokenize{using_katana/running_jobs:list-information-about-a-particular-job}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 src\PYG{o}{]}\PYGZdl{} qstat \PYGZhy{}f \PYG{l+m}{315236}
Job Id: \PYG{l+m}{315236}.kman.restech.unsw.edu.au
    \PYG{n+nv}{Job\PYGZus{}Name} \PYG{o}{=} job.pbs
    \PYG{n+nv}{Job\PYGZus{}Owner} \PYG{o}{=} z1234567@katana2
    \PYG{n+nv}{job\PYGZus{}state} \PYG{o}{=} Q
    \PYG{n+nv}{queue} \PYG{o}{=} general12
    \PYG{n+nv}{server} \PYG{o}{=} kman.gen
    \PYG{n+nv}{Checkpoint} \PYG{o}{=} u
    \PYG{n+nv}{ctime} \PYG{o}{=} Fri May  \PYG{l+m}{1} \PYG{l+m}{14}:41:00 \PYG{l+m}{2020}
    \PYG{n+nv}{Error\PYGZus{}Path} \PYG{o}{=} katana2:/home/z1234567/src/job.pbs.e315236
    \PYG{n+nv}{group\PYGZus{}list} \PYG{o}{=} GENERAL
    \PYG{n+nv}{Hold\PYGZus{}Types} \PYG{o}{=} n
    \PYG{n+nv}{Join\PYGZus{}Path} \PYG{o}{=} n
    \PYG{n+nv}{Keep\PYGZus{}Files} \PYG{o}{=} n
    \PYG{n+nv}{Mail\PYGZus{}Points} \PYG{o}{=} a
    \PYG{n+nv}{mtime} \PYG{o}{=} Fri May  \PYG{l+m}{1} \PYG{l+m}{14}:41:00 \PYG{l+m}{2020}
    \PYG{n+nv}{Output\PYGZus{}Path} \PYG{o}{=} katana2:/home/z1234567/src/job.pbs.o315236
    \PYG{n+nv}{Priority} \PYG{o}{=} \PYG{l+m}{0}
    \PYG{n+nv}{qtime} \PYG{o}{=} Fri May  \PYG{l+m}{1} \PYG{l+m}{14}:41:00 \PYG{l+m}{2020}
    \PYG{n+nv}{Rerunable} \PYG{o}{=} True
    Resource\PYGZus{}List.ib \PYG{o}{=} no
    Resource\PYGZus{}List.mem \PYG{o}{=} 1gb
    Resource\PYGZus{}List.ncpus \PYG{o}{=} \PYG{l+m}{1}
    Resource\PYGZus{}List.ngpus \PYG{o}{=} \PYG{l+m}{0}
    Resource\PYGZus{}List.nodect \PYG{o}{=} \PYG{l+m}{1}
    Resource\PYGZus{}List.place \PYG{o}{=} pack
    Resource\PYGZus{}List.select \PYG{o}{=} \PYG{l+m}{1}:mem\PYG{o}{=}1gb:ncpus\PYG{o}{=}\PYG{l+m}{1}
    Resource\PYGZus{}List.walltime \PYG{o}{=} \PYG{l+m}{01}:00:00
    \PYG{n+nv}{substate} \PYG{o}{=} \PYG{l+m}{10}
    \PYG{n+nv}{Variable\PYGZus{}List} \PYG{o}{=} \PYG{n+nv}{PBS\PYGZus{}O\PYGZus{}HOME}\PYG{o}{=}/home/z1234567,PBS\PYGZus{}O\PYGZus{}LANG\PYG{o}{=}en\PYGZus{}AU.UTF\PYGZhy{}8,
        \PYG{n+nv}{PBS\PYGZus{}O\PYGZus{}LOGNAME}\PYG{o}{=}z1234567,
        \PYG{n+nv}{PBS\PYGZus{}O\PYGZus{}PATH}\PYG{o}{=}/home/z1234567/bin:/usr/lib64/qt\PYGZhy{}3.3/bin:/usr/lib64/ccache:
        /usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/pbs/bin,PBS\PYGZus{}O\PYGZus{}M
        \PYG{n+nv}{AIL}\PYG{o}{=}/var/spool/mail/z1234567,PBS\PYGZus{}O\PYGZus{}SHELL\PYG{o}{=}/bin/bash,PBS\PYGZus{}O\PYGZus{}WORKDIR\PYG{o}{=}/home
        /z1234567/src,PBS\PYGZus{}O\PYGZus{}SYSTEM\PYG{o}{=}Linux,PBS\PYGZus{}O\PYGZus{}QUEUE\PYG{o}{=}submission,PBS\PYGZus{}O\PYGZus{}HOST\PYG{o}{=}kat
        ana2
    \PYG{n+nv}{etime} \PYG{o}{=} Fri May  \PYG{l+m}{1} \PYG{l+m}{14}:41:00 \PYG{l+m}{2020}
    \PYG{n+nv}{eligible\PYGZus{}time} \PYG{o}{=} \PYG{l+m}{00}:00:00
    \PYG{n+nv}{Submit\PYGZus{}arguments} \PYG{o}{=} \PYGZhy{}W \PYG{n+nv}{group\PYGZus{}list}\PYG{o}{=}GENERAL \PYGZhy{}N job.pbs job.pbs.JAZDNgL
    \PYG{n+nv}{project} \PYG{o}{=} \PYGZus{}pbs\PYGZus{}project\PYGZus{}default
\end{sphinxVerbatim}


\subsubsection{qdel}
\label{\detokenize{using_katana/running_jobs:qdel}}
Remove a job from the queue or kill it if it’s started. To remove an array job, you must include the square braces and they will need to be escaped. In that situation you use \sphinxcode{\sphinxupquote{qdel 12345\textbackslash{}{[}\textbackslash{}{]}}}. Uses the \sphinxcode{\sphinxupquote{\$JOBID}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 src\PYG{o}{]}\PYGZdl{} qdel \PYG{l+m}{315252}
\end{sphinxVerbatim}


\subsubsection{qalter}
\label{\detokenize{using_katana/running_jobs:qalter}}
Once a job has been submitted, it can be altered. However, once a job begins execution, the only values that can be modified are \sphinxcode{\sphinxupquote{cputime}}, \sphinxcode{\sphinxupquote{walltime}}, and \sphinxcode{\sphinxupquote{run\_count}}. These can only be reduced.

Users can only lower resource requests on queued jobs. If you need to increase resources, contact a systems administrator. In this example you will see the resources change \sphinxhyphen{} but not the \sphinxcode{\sphinxupquote{Submit\_arguments}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 src\PYG{o}{]}\PYGZdl{} qsub \PYGZhy{}l \PYG{k}{select}\PYG{o}{=}\PYG{l+m}{1}:ncpus\PYG{o}{=}\PYG{l+m}{2}:mem\PYG{o}{=}128mb job.pbs
\PYG{l+m}{315259}.kman.restech.unsw.edu.au
\PYG{o}{[}z1234567@katana2 src\PYG{o}{]}\PYGZdl{} qstat \PYGZhy{}f \PYG{l+m}{315259}
Job Id: \PYG{l+m}{315259}.kman.restech.unsw.edu.au
    ...
    Resource\PYGZus{}List.mem \PYG{o}{=} 128mb
    Resource\PYGZus{}List.ncpus \PYG{o}{=} \PYG{l+m}{2}
    ...
    \PYG{n+nv}{Submit\PYGZus{}arguments} \PYG{o}{=} \PYGZhy{}W \PYG{n+nv}{group\PYGZus{}list}\PYG{o}{=}GENERAL \PYGZhy{}N job.pbs \PYGZhy{}l \PYG{k}{select}\PYG{o}{=}\PYG{l+m}{1}:ncpus\PYG{o}{=}\PYG{l+m}{2}:mem\PYG{o}{=}128mb job.pbs.YOOu3lB
    \PYG{n+nv}{project} \PYG{o}{=} \PYGZus{}pbs\PYGZus{}project\PYGZus{}default

\PYG{o}{[}z1234567@katana2 src\PYG{o}{]}\PYGZdl{} qalter \PYGZhy{}l \PYG{k}{select}\PYG{o}{=}\PYG{l+m}{1}:ncpus\PYG{o}{=}\PYG{l+m}{4}:mem\PYG{o}{=}512mb \PYG{l+m}{315259}\PYG{p}{;} qstat \PYGZhy{}f \PYG{l+m}{315259}
Job Id: \PYG{l+m}{315259}.kman.restech.unsw.edu.au
    ...
    Resource\PYGZus{}List.mem \PYG{o}{=} 512mb
    Resource\PYGZus{}List.ncpus \PYG{o}{=} \PYG{l+m}{4}
    ...
    \PYG{n+nv}{Submit\PYGZus{}arguments} \PYG{o}{=} \PYGZhy{}W \PYG{n+nv}{group\PYGZus{}list}\PYG{o}{=}GENERAL \PYGZhy{}N job.pbs \PYGZhy{}l \PYG{k}{select}\PYG{o}{=}\PYG{l+m}{1}:ncpus\PYG{o}{=}\PYG{l+m}{2}:mem\PYG{o}{=}128mb job.pbs.YOOu3lB
    \PYG{n+nv}{project} \PYG{o}{=} \PYGZus{}pbs\PYGZus{}project\PYGZus{}default
\end{sphinxVerbatim}


\subsection{Tips for using PBS and Katana effectively}
\label{\detokenize{using_katana/running_jobs:tips-for-using-pbs-and-katana-effectively}}\label{\detokenize{using_katana/running_jobs:scheduler-tips}}

\subsubsection{Keep your jobs under 12 hours if possible}
\label{\detokenize{using_katana/running_jobs:keep-your-jobs-under-12-hours-if-possible}}
If you request more than 12 hours of \sphinxcode{\sphinxupquote{WALLTIME}} then you can only use the nodes bought by your school or research group. Keeping your job’s run time request under 12 hours means that it can run on any node in the cluster.

\begin{sphinxadmonition}{important}{Important:}
Two 10 hour jobs will probably finish sooner that one 20 hour job.
\end{sphinxadmonition}

In fact, if there is spare capacity on Katana, which there is most of the time, six 10 hours jobs will finish before a single 20 hour job will.
Requesting more resources for your job decreases the places that the job can run

The most obvious example is going over the 12 hour limit which limits the number of compute nodes that your job can run on but it is worth . For example specifying the CPU in your job script restricts you to the nodes with that CPU. A job that requests 20Gb will run on a 128Gb node with a 100Gb job already running but a 30Gb job will not be able to.


\subsubsection{Running your jobs interactively makes it hard to manage multiple concurrent jobs}
\label{\detokenize{using_katana/running_jobs:running-your-jobs-interactively-makes-it-hard-to-manage-multiple-concurrent-jobs}}
If you are currently only running jobs interactively then you should move to batch jobs which allow you to submit more jobs which then start, run and finish automatically.
If you have multiple batch jobs that are almost identical then you should consider using array jobs

If your batch jobs are the same except for a change in file name or another variable then you should have a look at using array jobs.


\section{GitHub}
\label{\detokenize{using_katana/github:github}}\label{\detokenize{using_katana/github::doc}}
Version control systems like GitHub record changes to files over time, allowing you to go back to older versions, and create new branches for experimentation.

Version control is most useful for keeping track of programming code and documentation \sphinxhyphen{} large text based corpora that aren’t suitable for storing in databases.

\sphinxhref{https://github.com/unsw-edu-au}{UNSW has an organisation in GitHub} for researchers and staff, joining this organisation gives you access to the UNSW\sphinxhyphen{}only repositories. There is even a UNSW specific LaTeX thesis template!
\begin{itemize}
\item {} 
\sphinxhref{https://github.com/unsw-edu-au/Restech-HPC/tree/master/hpc-examples}{Restech\sphinxhyphen{}HPC \sphinxhyphen{} Example job scripts for Katana and NCI}

\item {} 
\sphinxhref{https://github.com/unsw-edu-au/UNSW-Data-Archive}{UNSW\sphinxhyphen{}Data\sphinxhyphen{}Archive \sphinxhyphen{} Scripts for uploading to and downloading from the UNSW Data Archive}

\item {} 
\sphinxhref{https://github.com/unsw-edu-au/UNSW-eNotebook-LabArchives}{UNSW\sphinxhyphen{}eNotebook\sphinxhyphen{}LabArchives \sphinxhyphen{} UNSW eNotebook (LabArchives) widgets}

\end{itemize}


\subsection{How to sign up to the UNSW GitHub organisation}
\label{\detokenize{using_katana/github:how-to-sign-up-to-the-unsw-github-organisation}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Open \sphinxurl{https://myapps.microsoft.com}

\item {} 
Look to see if GitHub.com is in the list. If not then:

\end{enumerate}
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumi}{enumii}{}{.}%
\item {} 
Click on “+ Add app” at the top of the page

\item {} 
Click on “GitHub.com” and press “Add”

\item {} 
Wait until it appears in your list. This could take up to 40 minutes and you may need to refresh your browser.

\end{enumerate}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
Click on “GitHub.com” icon

\end{enumerate}
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumi}{enumii}{}{.}%
\item {} 
You will see “Single sign\sphinxhyphen{}on to UNSW Sydney”, press the green “continue” button to validate your UNSW identity with GitHub.

\item {} 
At this point GitHub requires you to maintain a local account and password as well as verifying your UNSW identity.  You can create a new GitHub identity, or sign in with an existing identity.  In either case, because you’ve navigated from myapps and validated your UNSW identity, you will be connected to the UNSW GitHub organisation.

\end{enumerate}


\chapter{Storage}
\label{\detokenize{storage/index:storage}}\label{\detokenize{storage/index:id1}}\label{\detokenize{storage/index::doc}}

\section{Storage Locations}
\label{\detokenize{storage/storage_locations:storage-locations}}\label{\detokenize{storage/storage_locations::doc}}
The storage on Katana is split into several different types, each of which serves a different purpose.

\begin{sphinxadmonition}{important}{Important:}
We have just said \sphinxstyleemphasis{each of which serves a different purpose}. Despite that, there will be overlap. And personal preference. In most cases it will be obvious where to put your information. If it isn’t and you need help with your decision making, you can \sphinxhref{mailto:rdm@unsw.edu.au}{email} the \sphinxhref{https://research.unsw.edu.au/research-data-management-unsw}{Research Data} team for advice. They are friendly people.
\end{sphinxadmonition}


\subsection{Cluster Home Drive}
\label{\detokenize{storage/storage_locations:cluster-home-drive}}

\subsubsection{Location}
\label{\detokenize{storage/storage_locations:location}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/home/z1234567
\end{sphinxVerbatim}


\subsubsection{Also known as}
\label{\detokenize{storage/storage_locations:also-known-as}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{}HOME}
\end{sphinxVerbatim}


\subsubsection{Attributes}
\label{\detokenize{storage/storage_locations:attributes}}\begin{itemize}
\item {} 
Backed up

\item {} 
10Gb limit

\item {} 
By default only user has access

\item {} 
Able to be used everywhere on Katana

\end{itemize}


\subsubsection{Best used for}
\label{\detokenize{storage/storage_locations:best-used-for}}
Source code and programs


\subsection{Global Scratch}
\label{\detokenize{storage/storage_locations:global-scratch}}

\subsubsection{Location}
\label{\detokenize{storage/storage_locations:id1}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/srv/scratch/z1234567
\end{sphinxVerbatim}


\subsubsection{Also known as}
\label{\detokenize{storage/storage_locations:id2}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/srv/scratch/\PYG{n+nv}{\PYGZdl{}USER}
\end{sphinxVerbatim}


\subsubsection{Attributes}
\label{\detokenize{storage/storage_locations:id3}}\begin{itemize}
\item {} 
Not available to users in STUDENT groups such as ESTUDENT.

\item {} 
Not backed up

\item {} 
Generally 16Tb shared between multiple users

\item {} 
By default only user has access

\item {} 
Able to be used everywhere on Katana

\end{itemize}


\subsubsection{Best used for}
\label{\detokenize{storage/storage_locations:id4}}
Data files


\subsection{Shared Scratch}
\label{\detokenize{storage/storage_locations:shared-scratch}}
Only available to groups of users that have requested it \sphinxhyphen{} primarily for teams that share data sets or results.


\subsubsection{Location}
\label{\detokenize{storage/storage_locations:id5}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/srv/scratch/name
\end{sphinxVerbatim}


\subsubsection{Attributes}
\label{\detokenize{storage/storage_locations:id6}}\begin{itemize}
\item {} 
Not backed up

\item {} 
Spaced based on group requirements

\item {} 
All users in the group have access

\item {} 
Able to be used everywhere on Katana

\end{itemize}


\subsubsection{Best used for}
\label{\detokenize{storage/storage_locations:id7}}
Shared data files and copies of programs


\subsection{Local Scratch}
\label{\detokenize{storage/storage_locations:local-scratch}}
Found on the node on which your job is running.


\subsubsection{Location}
\label{\detokenize{storage/storage_locations:id8}}
The location is created by the job scheduler as part of initialising the running of the job.


\subsubsection{Also known as}
\label{\detokenize{storage/storage_locations:id9}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{}TMPDIR}
\end{sphinxVerbatim}


\subsubsection{Attributes}
\label{\detokenize{storage/storage_locations:id10}}\begin{itemize}
\item {} 
Not backed up

\item {} 
Only exists whilst job is running

\item {} 
200Gb shared between node users

\item {} 
Storage located on compute node so good for compute

\end{itemize}


\subsubsection{Best used for}
\label{\detokenize{storage/storage_locations:id11}}
Much fast completion of jobs that require large datasets to be near the CPU, calculations and temp files.


\subsection{UNSW Research Storage}
\label{\detokenize{storage/storage_locations:unsw-research-storage}}

\subsubsection{Location}
\label{\detokenize{storage/storage_locations:id12}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/home/z1234567/sharename
\end{sphinxVerbatim}


\subsubsection{Also known as}
\label{\detokenize{storage/storage_locations:id13}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{}HOME}/sharename
\end{sphinxVerbatim}


\subsubsection{Attributes}
\label{\detokenize{storage/storage_locations:id14}}\begin{itemize}
\item {} 
Backed up

\item {} 
Only available on Katana head node

\end{itemize}


\subsubsection{Best used for}
\label{\detokenize{storage/storage_locations:id15}}
Shared and user data files.


\section{Katana Data Mover}
\label{\detokenize{storage/kdm:katana-data-mover}}\label{\detokenize{storage/kdm::doc}}
Also known as \sphinxcode{\sphinxupquote{kdm}} or \sphinxcode{\sphinxupquote{kdm.restech.unsw.edu.au}}

If you have data that you would like to copy to or within the Katana cluster, archive or even compress and decompress you should use the Katana Data Mover \sphinxhyphen{} also known as the KDM server \sphinxhyphen{} rather than using the head node. This section contains instructions on how to use KDM server.

If you are familiar with using Linux commands to copy or move files then you can do that directly by logging on to \sphinxcode{\sphinxupquote{kdm.restech.unsw.edu.au}} via \sphinxcode{\sphinxupquote{ssh}} in the same way that you would log in to Katana and then use the \sphinxcode{\sphinxupquote{cp}}, \sphinxcode{\sphinxupquote{mv}} and \sphinxcode{\sphinxupquote{rsync}} commands that you would normally use under Linux.

If you are not familiar with using the Linux command line for moving or copying files then the easiest way to move files around is to use client software such as \sphinxhref{https://filezilla-project.org/}{FileZilla}. Once you have connected to \sphinxcode{\sphinxupquote{kdm.restech.unsw.edu.au}} using your zID and zPass you should see a remote view which corresponds to the files sitting on Katana. You can then use the FileZilla interface to move files and folders around.

\begin{sphinxadmonition}{note}{Note:}
We require people to “move data” through the data mover. We have hundreds of users, most of whom have data ranging from very large to impossibly large. This is why we have the \sphinxcode{\sphinxupquote{kdm}}. If you are transferring a couple of small text files \sphinxhyphen{} job scripts for instance \sphinxhyphen{} you can copy directly to the Katana. But we would ask you to keep it to a minimum, and nothing bigger than 2\sphinxhyphen{}3 MB.
\end{sphinxadmonition}


\subsection{Copying Files To and From a Cluster}
\label{\detokenize{storage/kdm:copying-files-to-and-from-a-cluster}}
The method of transferring files to and from clusters depends on your local machine. If you are a Linux user then you should use rsync and if you are a Windows user then you should download and install \sphinxhref{https://winscp.net/eng/download.php}{WinSCP} or \sphinxhref{https://filezilla-project.org/}{FileZilla}


\subsubsection{Filezilla}
\label{\detokenize{storage/kdm:filezilla}}\label{\detokenize{storage/kdm:using-filezilla}}
Once you have installed Filezilla you can go into the site manager and create a new site in the site manager using the settings below.

\noindent\sphinxincludegraphics{{filezilla}.png}

You can also use the Quick Connect bar as shown here:

\noindent\sphinxincludegraphics{{filezillaquick}.png}


\subsubsection{From my computer to Katana Home}
\label{\detokenize{storage/kdm:from-my-computer-to-katana-home}}
To copy the directory \sphinxcode{\sphinxupquote{/home/1234567/my\sphinxhyphen{}directory}} from your local computer to Katana scratch. The trailing \sphinxcode{\sphinxupquote{:}} is important!

\begin{sphinxVerbatim}[commandchars=\\\{\}]
me@localhost:\PYGZti{}\PYGZdl{} rsync \PYGZhy{}avh /path/to/my\PYGZhy{}directory z1234567@kdm.restech.unsw.edu.au:
\end{sphinxVerbatim}


\subsubsection{From my computer to Katana Scratch}
\label{\detokenize{storage/kdm:from-my-computer-to-katana-scratch}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
me@localhost:\PYGZti{}\PYGZdl{} rsync \PYGZhy{}avh /path/to/my\PYGZhy{}directory z1234567@kdm.restech.unsw.edu.au:/srv/scratch/z1234567
\end{sphinxVerbatim}


\subsubsection{From Katana to my computer}
\label{\detokenize{storage/kdm:from-katana-to-my-computer}}
First, you need to make sure the data is in either your Home directory or your scratch

If the data is in \sphinxcode{\sphinxupquote{/home/z1234567/my\sphinxhyphen{}remote\sphinxhyphen{}results}} and you want it in your home directory:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
me@localhost:\PYGZti{}\PYGZdl{} rsync \PYGZhy{}avh z1234567@kdm.restech.unsw.edu.au:my\PYGZhy{}remote\PYGZhy{}results /home/me/
\end{sphinxVerbatim}

If the data is in \sphinxcode{\sphinxupquote{/srv/scratch/my\sphinxhyphen{}remote\sphinxhyphen{}results}} and you want it in your home directory:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
me@localhost:\PYGZti{}\PYGZdl{} rsync \PYGZhy{}avh z1234567@kdm.restech.unsw.edu.au:/srv/scratch/my\PYGZhy{}remote\PYGZhy{}results /home/me
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
{\hyperref[\detokenize{software/tmux:tmux}]{\sphinxcrossref{\DUrole{std,std-ref}{TMUX}}}} is available if your data is large and the rsync might take a long time.
\end{sphinxadmonition}


\section{How to use the UNSW Data Archive}
\label{\detokenize{storage/data_archive:how-to-use-the-unsw-data-archive}}\label{\detokenize{storage/data_archive::doc}}
The UNSW Data Archive is the primary research storage facility provided by UNSW. The Data Archive gives UNSW researchers a free, safe and secure storage service to store and access research data well beyond the life of the project that collected that data.

To help researchers make use of this system the Katana Data Mover has a script that you can use to copy files from Katana into a project on the Data Archive system.

\begin{sphinxadmonition}{note}{Note:}
To use this script you must have access to the UNSW Data Archive which requires setting up a \sphinxhref{https://research.unsw.edu.au/research-data-management-unsw}{Research Data Management Plan}.
\end{sphinxadmonition}

The best documentation on how to use the \sphinxhref{http://www.dataarchive.unsw.edu.au/}{Data Archive} is found on their website:
\begin{itemize}
\item {} 
using the \sphinxhref{http://www.dataarchive.unsw.edu.au/help/web-application-guide}{web application}

\item {} 
using \sphinxhref{http://www.dataarchive.unsw.edu.au/help/sftp-client-guide}{SFTP}

\item {} 
using the \sphinxhref{http://www.dataarchive.unsw.edu.au/help/command-line-script-guide}{Command Line}

\end{itemize}

To see what versions of the Data Archive script are available log on to \sphinxcode{\sphinxupquote{kdm.science.unsw.edu.au}} and type

\begin{sphinxVerbatim}[commandchars=\\\{\}]
module avail unswdataarchive
\end{sphinxVerbatim}

Use the help command for usage

\begin{sphinxVerbatim}[commandchars=\\\{\}]
module \PYG{n+nb}{help} unswdataarchive/2020\PYGZhy{}03\PYGZhy{}19
\end{sphinxVerbatim}

\begin{sphinxadmonition}{warning}{Warning:}
This advice has poor results. The help file is too long for most screen sizes and there’s no pagination in modules version < 4. Last line should include a location that the researcher can read directly (using less)
\end{sphinxadmonition}


\subsection{Initial Setup}
\label{\detokenize{storage/data_archive:initial-setup}}
To use the Data Archive you need to set up a configuration file. Here’s how to create the generic config in the directory you are in:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
[z1234567@kdm \PYGZti{}]\PYGZdl{} module add unswdataarchive/2020\PYGZhy{}03\PYGZhy{}19
[z1234567@kdm \PYGZti{}]\PYGZdl{} get\PYGZhy{}config\PYGZhy{}file
\end{sphinxVerbatim}

Before you use the script for the first time you will need to generate a token for uploading data to the archive. To generate a token send an email to the \sphinxhref{mailto:ITServiceCentre@unsw.edu.au}{IT Service Centre} asking for a Data Archive token to be generated.

Then edit the configuration file \sphinxcode{\sphinxupquote{config.cfg}} and to change the line that looks like \sphinxcode{\sphinxupquote{token=}}

If you haven’t generated a token you can also upload content using your zID and zPass by adding the following line to the file \sphinxcode{\sphinxupquote{config.cfg}} and you will be asked for your zPass when you start the upload.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nv}{user}\PYG{o}{=}z1234567
\end{sphinxVerbatim}


\subsection{Starting a data transfer}
\label{\detokenize{storage/data_archive:starting-a-data-transfer}}
To get data \sphinxstylestrong{into} the archive, we use \sphinxcode{\sphinxupquote{upload.sh}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
upload.sh /path/to/your/local/directory /UNSW\PYGZus{}RDS/D0000000/your/collection/name
\end{sphinxVerbatim}

To get data \sphinxstylestrong{from} the archive, we use \sphinxcode{\sphinxupquote{download.sh}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
download.sh /UNSW\PYGZus{}RDS/D0000000/your/collection/name /path/to/your/local/directory
\end{sphinxVerbatim}


\chapter{Software}
\label{\detokenize{software/index:software}}\label{\detokenize{software/index:id1}}\label{\detokenize{software/index::doc}}
This section starts with Environment Modules to help you get started using the software we have installed on Katana.

Each section after that explains tips and tricks for using that software on Katana and a link to an example batch script in our Github examples.


\section{Environment Modules}
\label{\detokenize{software/environment_modules:environment-modules}}\label{\detokenize{software/environment_modules::doc}}
Environment Modules offer a simple means of customising your environment to access the required versions of installed software and this section provides information on how they are used on Katana.

When we use modules, we are changing our “environment”, hence the name.


\subsection{How do I discover what software is available?}
\label{\detokenize{software/environment_modules:how-do-i-discover-what-software-is-available}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana \PYGZti{}\PYG{o}{]}\PYGZdl{} module avail

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} /share/apps/modules/intel \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
intel/11.1.080\PYG{o}{(}default\PYG{o}{)}  intel/12.1.7.367  intel/13.0.1.117  intel/13.1.0.146

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} /share/apps/modules/pgi \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
pgi/13.7

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} /share/apps/modules/matlab \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
matlab/2007b          matlab/2010b          matlab/2012a\PYG{o}{(}default\PYG{o}{)}
matlab/2008b          matlab/2011a          matlab/2012b
matlab/2009b          matlab/2011b          matlab/2013a
\end{sphinxVerbatim}


\subsection{What if the software that I want is not on the list?}
\label{\detokenize{software/environment_modules:what-if-the-software-that-i-want-is-not-on-the-list}}
If you require software installed on the cluster, email the \sphinxhref{mailto:ITServiceCentre@unsw.edu.au}{IT Service Centre} detailing the software that you would like installed and that you would like to have it installed on Katana. Please include links and desired version numbers.


\subsection{How do I add a particular version of software to my environment?}
\label{\detokenize{software/environment_modules:how-do-i-add-a-particular-version-of-software-to-my-environment}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} module add matlab/2018b
\end{sphinxVerbatim}

or

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} module load matlab/2018b
\end{sphinxVerbatim}


\subsection{How do I remove a particular version of software from my environment?}
\label{\detokenize{software/environment_modules:how-do-i-remove-a-particular-version-of-software-from-my-environment}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} module rm matlab/2018b
\end{sphinxVerbatim}

or

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} module unload matlab/2018b
\end{sphinxVerbatim}


\subsection{How do I remove all modules from my environment?}
\label{\detokenize{software/environment_modules:how-do-i-remove-all-modules-from-my-environment}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} module purge
\end{sphinxVerbatim}


\subsection{Which versions of software am I currently using?}
\label{\detokenize{software/environment_modules:which-versions-of-software-am-i-currently-using}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} module list
Currently Loaded Modulefiles:
 \PYG{l+m}{1}\PYG{o}{)} intel/18.0.1.163   \PYG{l+m}{2}\PYG{o}{)} matlab/2018b
\end{sphinxVerbatim}


\subsection{How do I find out more about a particular piece of software?}
\label{\detokenize{software/environment_modules:how-do-i-find-out-more-about-a-particular-piece-of-software}}
You can find out more about a piece of software by using the module help command. For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} module \PYG{n+nb}{help} mrbayes

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} Module Specific Help \PYG{k}{for} \PYG{l+s+s1}{\PYGZsq{}mrbayes/3.2.2\PYGZsq{}} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

MrBayes \PYG{l+m}{3}.2.2 is installed in /apps/mrbayes/3.2.2

This module was complied against beagle/2.1.2 and openmpi/1.6.4 with MPI support.

More information about the commands made available by this module is available
at http://mrbayes.sourceforge.net
\end{sphinxVerbatim}


\subsection{How do I switch between particular versions of software?}
\label{\detokenize{software/environment_modules:how-do-i-switch-between-particular-versions-of-software}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} module switch matlab/2018b matlab/2017b
\end{sphinxVerbatim}


\subsection{How can I find out what paths and other environment variables a module uses?}
\label{\detokenize{software/environment_modules:how-can-i-find-out-what-paths-and-other-environment-variables-a-module-uses}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} module show mothur/1.42.3
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
/apps/modules/bio/mothur/1.42.3:

module\PYGZhy{}whatis     Mothur \PYG{l+m}{1}.42.3
conflict     mothur
setenv         MOTHUR\PYGZus{}ROOT /apps/mothur/1.42.3
prepend\PYGZhy{}path     PATH /apps/mothur/1.42.3/bin
setenv         LAST\PYGZus{}MODULE\PYGZus{}TYPE bio
setenv         LAST\PYGZus{}MODULE\PYGZus{}NAME mothur/1.42.3
setenv         LAST\PYGZus{}MODULE\PYGZus{}VERSION \PYG{l+m}{1}.42.3
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\end{sphinxVerbatim}


\subsection{Why does the cluster forget my choice of modules?}
\label{\detokenize{software/environment_modules:why-does-the-cluster-forget-my-choice-of-modules}}
Environment modules only affect the particular session in which they are loaded. Loading a module in one SSH session will not affect any other SSH session or even any jobs submitted from that session. Modules must be loaded in every session where they will be used.


\subsection{How can I invoke my module commands automatically?}
\label{\detokenize{software/environment_modules:how-can-i-invoke-my-module-commands-automatically}}
The best way of doing this is to add your Module commands to your job scripts. This approach is useful for preserving the required environment for each job. For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/bin/bash}

\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l nodes=1:ppn=1}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}l vmem=4gb}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}j oe}

module purge
module add intel/18.0.1.163

\PYG{n+nb}{cd} \PYG{l+s+si}{\PYGZdl{}\PYGZob{}}\PYG{n+nv}{PBS\PYGZus{}O\PYGZus{}WORKDIR}\PYG{l+s+si}{\PYGZcb{}}

./myprog
\end{sphinxVerbatim}

Perl, Python and R all have their own library/module systems \sphinxhyphen{} \sphinxhref{https://www.cpan.org/}{CPAN}, \sphinxhref{https://pypi.org/}{PyPI} and \sphinxhref{https://cran.r-project.org/}{CRAN}. If a library or module you want from one of these sources isn’t installed in the module, please email us at \sphinxhref{mailto:ITServiceCentre@unsw.edu.au?subject=KatanaSoftwareInstall}{IT Service Desk}


\section{Biosciences}
\label{\detokenize{software/biosciences:biosciences}}\label{\detokenize{software/biosciences::doc}}
Bioconductor, BioPerl, BioPython, Blast+, Mothur are all installed.


\section{Java}
\label{\detokenize{software/java:java}}\label{\detokenize{software/java::doc}}
Java is installed as part of the Operating System but we would strongly recommend against using that version \sphinxhyphen{} we cannot guarantee scientific reproducibility with that version. Please use the java modules.

Each Java module sets

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZus{}JAVA\PYGZus{}TOOL\PYGZus{}OPTIONS \PYGZhy{}Xmx1g
\end{sphinxVerbatim}

This sets the heap memory to 1GB. If you need more, set the environment variable \sphinxcode{\sphinxupquote{\_JAVA\_OPTIONS}} which overrides \sphinxcode{\sphinxupquote{\_JAVA\_TOOL\_OPTIONS}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{export} \PYG{n+nv}{\PYGZus{}JAVA\PYGZus{}OPTIONS}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZhy{}Xmx5g\PYGZdq{}}
\end{sphinxVerbatim}


\section{Intel Compilers and Software Libraries}
\label{\detokenize{software/intel_compilers_and_libraries:intel-compilers-and-software-libraries}}\label{\detokenize{software/intel_compilers_and_libraries::doc}}
Research Technology Services has a licence for Intel Compiler Collection which can be accessed by loading a module and contains 3 groups of software, namely compilers, libraries and a debugger. This software has been optimised by Intel to take advantage of the specific capabilities of the different intel CPUs installed in the Intel based clusters.
\begin{itemize}
\item {} \begin{description}
\item[{Compilers}] \leavevmode\begin{itemize}
\item {} 
Intel C Compiler (icc)

\item {} 
Intel C++ Compiler (icpc)

\item {} 
Intel Fortran Compiler (ifort)

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{Libraries}] \leavevmode\begin{itemize}
\item {} 
Intel Math Kernel Library (MKL)

\item {} 
Intel Threading Building Blocks (TBB)

\item {} 
Intel Integrated Performance Primitives (IPP)

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{Debugger}] \leavevmode\begin{itemize}
\item {} 
Intel Debugger (idbc)

\end{itemize}

\end{description}

\end{itemize}


\section{Operating Systems}
\label{\detokenize{software/operating_systems:operating-systems}}\label{\detokenize{software/operating_systems::doc}}
Katana nodes are running either RedHat 7.8 (management plane) or CentOS 7.8 (compute nodes).

Research software is installed in modules so that they can be loaded or unloaded as necessary. This way we can offer and run multiple versions of each package at the same time.


\section{Perl}
\label{\detokenize{software/perl:perl}}\label{\detokenize{software/perl::doc}}
The default version of Perl on Katana is 5.16.3 which is provided by CentOS 7 and can be found at \sphinxcode{\sphinxupquote{/usr/bin/perl}}.

This is an older version of Perl. We have Perl 5.28.0 installed as a module.

It is common for perl scripts to begin with

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/usr/bin/perl}
\end{sphinxVerbatim}

If you are using the Perl module, you will need to change the first line to

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/usr/bin/env perl}
\end{sphinxVerbatim}


\section{Python}
\label{\detokenize{software/python:python}}\label{\detokenize{software/python::doc}}
It is common for python scripts to begin with

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/usr/bin/python}
\end{sphinxVerbatim}

If you are using a Python module, you will need to change the first line to

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/usr/bin/env python}
\end{sphinxVerbatim}

or more the likely

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/usr/bin/env python3}
\end{sphinxVerbatim}


\subsection{Conda and Anaconda}
\label{\detokenize{software/python:conda-and-anaconda}}
We get a lot of questions about installing Conda and Anaconda. Unfortunately neither are designed to be installed in multi\sphinxhyphen{}user environments.

You are able to install them into your home directory and we encourage you to do so.

Alternatively, many packages will give you an option for a \sphinxcode{\sphinxupquote{pip install}} \sphinxhyphen{} if this is an option, we recommend you use \sphinxcode{\sphinxupquote{python virtual environments}}.


\subsection{Virtual Environments}
\label{\detokenize{software/python:virtual-environments}}
We encourage researchers to utilise the power of {\hyperref[\detokenize{software/python-virtualenvs:python-virtual-environments}]{\sphinxcrossref{\DUrole{std,std-ref}{Python Virtual Environments}}}} if they are developing their own software or want to use packages that aren’t installed.


\section{Python Virtual Environments}
\label{\detokenize{software/python-virtualenvs:python-virtual-environments}}\label{\detokenize{software/python-virtualenvs::doc}}

\subsection{or how to run a python library until the admins install it (or what to do if they wont install it)}
\label{\detokenize{software/python-virtualenvs:or-how-to-run-a-python-library-until-the-admins-install-it-or-what-to-do-if-they-wont-install-it}}

\subsubsection{Background}
\label{\detokenize{software/python-virtualenvs:background}}
Sometimes you will need to use a particular version of Python, or you will need to use a set of Python libraries that aren’t available in the provided installation.

In these cases, we can use what’s known as a \sphinxstyleemphasis{virtual environment} or \sphinxstyleemphasis{venv}. A venv gives us a static version of Python in our home directory in which we can install any packages we like.

In this tutorial we will see how to set up a venv and explain what’s happening under the hood. Then we will show how you can use one in your development process. As a note, in this walk through we will refer to packages and libraries as “packages”. When we use these terms, we are referring to a collection of files, written in Python, usually with some versions and potentially some requirements of their own.


\subsubsection{Setting up the default environment}
\label{\detokenize{software/python-virtualenvs:setting-up-the-default-environment}}
According to the \sphinxhref{https://docs.python.org/3/library/venv.html}{Python documentation}, we will run something like this \sphinxcode{\sphinxupquote{python3 \sphinxhyphen{}m venv /path/to/new/virtual/environment}}. This is not a directory that we need to see or need to spend time in actively, so it’s ok to make it hidden. This is an important distinction \sphinxhyphen{} the \sphinxstyleemphasis{venv} should not be where you are doing your development. It’s meant to be flexible \sphinxhyphen{} as soon as you fill it with development code, it’s no longer flexible. Also, you want your development code backed up or in a repository \sphinxhyphen{} it is unnecessary bloat to add the Python software to that backup or repository.

We will make a directory in which we can keep many venvs. What I found was that once I started using venvs, it didn’t make any sense to do Python development without them.

In Linux we can make a directory or file invisible by naming it with a leading dot:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} mkdir /home/z1234567/.venvs/
\end{sphinxVerbatim}


\subsubsection{Setting up the virtual environment \sphinxhyphen{} creation and activation}
\label{\detokenize{software/python-virtualenvs:setting-up-the-virtual-environment-creation-and-activation}}
I’ll be using the latest version of Python available to me. Since this is one of the modules that we offer, I can use it with the understanding that it will be there indefinitely.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} module load python/3.7.4
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} which python3
/apps/python/3.7.4/bin/python3
z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} python3 \PYGZhy{}m venv /home/z1234567/.venvs/venv\PYGZhy{}tutorial\PYGZhy{}1
\end{sphinxVerbatim}

That’s it, we are done. If you want to take a look under the hood, see \sphinxhref{python-virtualenvs-internals.rst}{what’s in my virtualenv?}

Next, we need to \sphinxstylestrong{activate} our venv. This makes our virtualenv our current environment. To activate, we execute \sphinxcode{\sphinxupquote{source /path/to/venv/bin/activate}}. Note that after activation, the prompt changes to make it clear you are now in a venv. You can see the change in which versions of \sphinxcode{\sphinxupquote{python3}} and \sphinxcode{\sphinxupquote{pip3}} are available before and after activation:

Before we activate our environment

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} which python3\PYG{p}{;} which pip3
/apps/python/3.7.4/bin/python3
/apps/python/3.7.4/bin/pip3
\end{sphinxVerbatim}

Activation

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} \PYG{n+nb}{source} \PYGZti{}/.venvs/venv\PYGZhy{}tutorial\PYGZhy{}1/bin/activate
\end{sphinxVerbatim}

After activation, our python binaries are not the defaults, but the versions in our \sphinxstyleemphasis{venv}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{(}venv\PYGZhy{}tutorial\PYGZhy{}1\PYG{o}{)} \PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} which python3\PYG{p}{;} which pip3
\PYGZti{}/.venvs/venv\PYGZhy{}tutorial\PYGZhy{}1/bin/python3
\PYGZti{}/.venvs/venv\PYGZhy{}tutorial\PYGZhy{}1/bin/pip3
\end{sphinxVerbatim}


\subsubsection{pip3 \sphinxhyphen{} the Python package manager (“the \sphinxstyleemphasis{Package Installer for Python}”)}
\label{\detokenize{software/python-virtualenvs:pip3-the-python-package-manager-the-package-installer-for-python}}
Using \sphinxhref{https://pypi.org/project/pip/}{pip3} we can see whats installed and install new packages. You will often see packages give installation advice for pip (Conda is another popular system).

Now that we are using the venv, we can list what’s in the venv, and then install a new package:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{(}venv\PYGZhy{}tutorial\PYGZhy{}1\PYG{o}{)} \PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} pip3 list
Package    Version
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
pip        \PYG{l+m}{19}.0.3
setuptools \PYG{l+m}{40}.8.0
You are using pip version \PYG{l+m}{19}.0.3, however version \PYG{l+m}{20}.0.2 is available.
You should consider upgrading via the \PYG{l+s+s1}{\PYGZsq{}pip install \PYGZhy{}\PYGZhy{}upgrade pip\PYGZsq{}} command.
\end{sphinxVerbatim}

At this point \sphinxhyphen{} before any work is done, and while using your venv \sphinxhyphen{} it’s a great time to perform that update.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{(}venv\PYGZhy{}tutorial\PYGZhy{}1\PYG{o}{)} \PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} pip install \PYGZhy{}\PYGZhy{}upgrade pip
Collecting pip
  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip\PYGZhy{}20.0.2\PYGZhy{}py2.py3\PYGZhy{}none\PYGZhy{}any.whl \PYG{o}{(}\PYG{l+m}{1}.4MB\PYG{o}{)}
    \PYG{l+m}{100}\PYGZpc{} \PYG{p}{|}████████████████████████████████\PYG{p}{|} \PYG{l+m}{1}.4MB \PYG{l+m}{1}.5MB/s
Installing collected packages: pip
  Found existing installation: pip \PYG{l+m}{19}.0.3
    Uninstalling pip\PYG{l+s+se}{\PYGZbs{}\PYGZhy{}}\PYG{l+m}{19}.0.3:
    Successfully uninstalled pip\PYG{l+s+se}{\PYGZbs{}\PYGZhy{}}\PYG{l+m}{19}.0.3
Successfully installed pip\PYGZhy{}20.0.2
\PYG{o}{(}venv\PYGZhy{}tutorial\PYGZhy{}1\PYG{o}{)} \PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} pip install \PYGZhy{}\PYGZhy{}upgrade setuptools
Collecting setuptools
  Downloading setuptools\PYGZhy{}46.1.1\PYGZhy{}py3\PYGZhy{}none\PYGZhy{}any.whl \PYG{o}{(}\PYG{l+m}{582} kB\PYG{o}{)}
     \PYG{p}{|}████████████████████████████████\PYG{p}{|} \PYG{l+m}{582} kB \PYG{l+m}{13}.5 MB/s
Installing collected packages: setuptools
  Attempting uninstall: setuptools
    Found existing installation: setuptools \PYG{l+m}{40}.8.0
            Uninstalling setuptools\PYG{l+s+se}{\PYGZbs{}\PYGZhy{}}\PYG{l+m}{40}.8.0:
          Successfully uninstalled setuptools\PYG{l+s+se}{\PYGZbs{}\PYGZhy{}}\PYG{l+m}{40}.8.0
Successfully installed setuptools\PYGZhy{}46.1.1
\PYG{o}{(}venv\PYGZhy{}tutorial\PYGZhy{}1\PYG{o}{)} \PYG{o}{[}z1234567@katana2 w\PYGZti{}\PYG{o}{]}\PYGZdl{} pip3 list
Package    Version
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
pip        \PYG{l+m}{20}.0.2
setuptools \PYG{l+m}{46}.1.1
\end{sphinxVerbatim}


\subsubsection{Installing software}
\label{\detokenize{software/python-virtualenvs:installing-software}}
And then package installation is as easy as using \sphinxcode{\sphinxupquote{pip install ...}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{(}venv\PYGZhy{}tutorial\PYGZhy{}1\PYG{o}{)} \PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} pip install numpy
Collecting numpy
  Downloading numpy\PYGZhy{}1.18.2\PYGZhy{}cp37\PYGZhy{}cp37m\PYGZhy{}manylinux1*x86*64.whl \PYG{o}{(}\PYG{l+m}{20}.2 MB\PYG{o}{)}
     \PYG{p}{|}████████████████████████████████\PYG{p}{|} \PYG{l+m}{20}.2 MB \PYG{l+m}{38} kB/s
Installing collected packages: numpy
Successfully installed numpy\PYGZhy{}1.18.2
\PYG{o}{(}venv\PYGZhy{}tutorial\PYGZhy{}1\PYG{o}{)} \PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} pip list
Package    Version
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
numpy      \PYG{l+m}{1}.18.2
pip        \PYG{l+m}{20}.0.2
setuptools \PYG{l+m}{46}.1.1
\end{sphinxVerbatim}


\subsubsection{Exiting the venv, and coming around again}
\label{\detokenize{software/python-virtualenvs:exiting-the-venv-and-coming-around-again}}
To leave a venv, you use the \sphinxcode{\sphinxupquote{deactivate}} command like this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{(}venv\PYGZhy{}tutorial\PYGZhy{}1\PYG{o}{)} \PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} deactivate
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{}
\end{sphinxVerbatim}

Notice how the prompt returned to the way it was? Let’s create a new venv:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} python3 \PYGZhy{}m venv /home/z1234567/.venvs/scipy\PYGZhy{}example
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} ls \PYGZhy{}l \PYGZti{}/.venvs/
total \PYG{l+m}{0}
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{5} z1234567 unsw \PYG{l+m}{69} Mar \PYG{l+m}{23} \PYG{l+m}{15}:07 scipy\PYGZhy{}example
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{5} z1234567 unsw \PYG{l+m}{69} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 venv\PYGZhy{}tutorial\PYGZhy{}1
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} \PYG{n+nb}{source} \PYGZti{}/.venvs/scipy\PYGZhy{}example/bin/activate
\PYG{o}{(}scipy\PYGZhy{}example\PYG{o}{)} \PYG{o}{[}z1234567@katana2 src\PYG{o}{]}\PYGZdl{}
\PYG{o}{(}scipy\PYGZhy{}example\PYG{o}{)} \PYG{o}{[}z1234567@katana2 src\PYG{o}{]}\PYGZdl{} pip list
Package    Version
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
pip        \PYG{l+m}{19}.0.3
setuptools \PYG{l+m}{40}.8.0
You are using pip version \PYG{l+m}{19}.0.3, however version \PYG{l+m}{20}.0.2 is available.
You should consider upgrading via the \PYG{l+s+s1}{\PYGZsq{}pip install \PYGZhy{}\PYGZhy{}upgrade pip\PYGZsq{}} command.
\end{sphinxVerbatim}

When we install SciPy, it automatically knows to install NumPy, a dependency:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{(}scipy\PYGZhy{}example\PYG{o}{)} \PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} pip install scipy
Collecting scipy
  Downloading scipy\PYGZhy{}1.4.1\PYGZhy{}cp37\PYGZhy{}cp37m\PYGZhy{}manylinux1*x86*64.whl \PYG{o}{(}\PYG{l+m}{26}.1 MB\PYG{o}{)}
     \PYG{p}{|}████████████████████████████████\PYG{p}{|} \PYG{l+m}{26}.1 MB \PYG{l+m}{95} kB/s
Collecting numpy\PYGZgt{}\PYG{o}{=}\PYG{l+m}{1}.13.3
  Using cached numpy\PYGZhy{}1.18.2\PYGZhy{}cp37\PYGZhy{}cp37m\PYGZhy{}manylinux1*x86*64.whl \PYG{o}{(}\PYG{l+m}{20}.2 MB\PYG{o}{)}
Installing collected packages: numpy, scipy
Successfully installed numpy\PYGZhy{}1.18.2 scipy\PYGZhy{}1.4.1
\PYG{o}{(}scipy\PYGZhy{}example\PYG{o}{)} \PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} pip list
Package    Version
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
numpy      \PYG{l+m}{1}.18.2
pip        \PYG{l+m}{20}.0.2
scipy      \PYG{l+m}{1}.4.1
setuptools \PYG{l+m}{46}.1.1
\end{sphinxVerbatim}

If you want to install an older version, it’s relatively easy

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{(}old\PYGZhy{}scipy\PYGZhy{}example\PYG{o}{)} \PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} pip install \PYG{n+nv}{scipy}\PYG{o}{=}\PYG{o}{=}\PYG{l+m}{1}.2.3
Collecting \PYG{n+nv}{scipy}\PYG{o}{=}\PYG{o}{=}\PYG{l+m}{1}.2.3
  Downloading https://files.pythonhosted.org/packages/96/e7/e06976ab209ef44f0b3dc638b686338f68b8a2158a1b2c9036ac8677158a/scipy\PYGZhy{}1.2.3\PYGZhy{}cp37\PYGZhy{}cp37m\PYGZhy{}manylinux1\PYGZus{}x86\PYGZus{}64.whl \PYG{o}{(}\PYG{l+m}{24}.8MB\PYG{o}{)}
    \PYG{l+m}{100}\PYGZpc{} \PYG{p}{|}████████████████████████████████\PYG{p}{|} \PYG{l+m}{24}.8MB 239kB/s
Collecting numpy\PYGZgt{}\PYG{o}{=}\PYG{l+m}{1}.8.2 \PYG{o}{(}from \PYG{n+nv}{scipy}\PYG{o}{=}\PYG{o}{=}\PYG{l+m}{1}.2.3\PYG{o}{)}
  Using cached https://files.pythonhosted.org/packages/b7/ce/d0b92f0283faa4da76ea82587ff9da70104e81f59ba14f76c87e4196254e/numpy\PYGZhy{}1.18.2\PYGZhy{}cp37\PYGZhy{}cp37m\PYGZhy{}manylinux1\PYGZus{}x86\PYGZus{}64.whl
Installing collected packages: numpy, scipy
Successfully installed numpy\PYGZhy{}1.18.2 scipy\PYGZhy{}1.2.3
\PYG{o}{(}old\PYGZhy{}scipy\PYGZhy{}example\PYG{o}{)} \PYG{o}{[}z1234567@katana2 src\PYG{o}{]}\PYGZdl{} pip list
Package    Version
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
numpy      \PYG{l+m}{1}.18.2
pip        \PYG{l+m}{20}.0.2
scipy      \PYG{l+m}{1}.2.3
setuptools \PYG{l+m}{46}.1.1
\end{sphinxVerbatim}

That’s a quick introduction to how you can install Python packages locally.


\subsubsection{Special Cases}
\label{\detokenize{software/python-virtualenvs:special-cases}}
Say for instance you want to use software X in a Jupyter Notebook. X is already

installed on Katana.

In that case, your workflow would be:
\begin{itemize}
\item {} 
load the module in question

\item {} 
create the Virtual Environment with the flag \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}system\sphinxhyphen{}site\sphinxhyphen{}packages}}

\item {} 
install software in question with an understanding that you might not be able to get the latest release

\end{itemize}

For example, using the Katana TensorFlow installation and a desire for Jupyter:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} module load tensorflow/1.14gpu
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} python3 \PYGZhy{}m venv /home/z1234567/.venvs/tf \PYGZhy{}\PYGZhy{}system\PYGZhy{}site\PYGZhy{}packages
\PYG{o}{[}z1234567@katana1 \PYGZti{}\PYG{o}{]}\PYGZdl{} \PYG{n+nb}{source} \PYGZti{}/.venvs/tf/bin/activate
\PYG{o}{(}tf\PYG{o}{)} \PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} pip install jupyter
\end{sphinxVerbatim}

This will throw errors because there are a collection of packages missing in relation to the latest Jupyter. They shouldn’t affect your ability to run {\hyperref[\detokenize{software/python-jupyter-notebooks:jupyter-notebooks}]{\sphinxcrossref{\DUrole{std,std-ref}{Jupyter Notebooks}}}} with tensorflow.


\section{Virtual Environments from the inside}
\label{\detokenize{software/python-virtualenvs-internals:virtual-environments-from-the-inside}}\label{\detokenize{software/python-virtualenvs-internals::doc}}
We’ve built a venv in our \sphinxcode{\sphinxupquote{\textasciitilde{}/.venvs}} directory. Let’s take a look inside. This presumes you have used the command

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 src\PYG{o}{]}\PYGZdl{} python3 \PYGZhy{}m venv /home/z1234567/.venvs/venv\PYGZhy{}tutorial\PYGZhy{}1
\end{sphinxVerbatim}

to set up your virtualenv.

Here is a quick overview of the basics.

We can see there is a directory in \sphinxcode{\sphinxupquote{\textasciitilde{}/.venvs}} that has the same name as the virtualenv we created.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} ls \PYGZhy{}l \PYGZti{}/.venvs/
total \PYG{l+m}{0}
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}.  \PYG{l+m}{5} z1234567 unsw   \PYG{l+m}{69} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 venv\PYGZhy{}tutorial\PYGZhy{}1
\end{sphinxVerbatim}

Inside that directory we can see some more directories. The two important directories here are \sphinxcode{\sphinxupquote{bin}} and \sphinxcode{\sphinxupquote{lib}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} ls \PYGZhy{}l \PYGZti{}/.venvs/venv\PYGZhy{}tutorial\PYGZhy{}1/
total \PYG{l+m}{8}
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{2} z1234567 unsw \PYG{l+m}{4096} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 bin
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{2} z1234567 unsw    \PYG{l+m}{6} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 include
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{3} z1234567 unsw   \PYG{l+m}{22} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 lib
lrwxrwxrwx. \PYG{l+m}{1} z1234567 unsw    \PYG{l+m}{3} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 lib64 \PYGZhy{}\PYGZgt{} lib
\PYGZhy{}rw\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{1} z1234567 unsw   \PYG{l+m}{83} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 pyvenv.cfg
\end{sphinxVerbatim}

In \sphinxcode{\sphinxupquote{bin}} you will see executables. The main one of note is \sphinxcode{\sphinxupquote{activate}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} ls \PYGZhy{}l \PYGZti{}/.venvs/venv\PYGZhy{}tutorial\PYGZhy{}1/bin/
total \PYG{l+m}{36}
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{2} z1234567 unsw \PYG{l+m}{4096} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 .
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{5} z1234567 unsw   \PYG{l+m}{69} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 ..
\PYGZhy{}rw\PYGZhy{}r\PYGZhy{}\PYGZhy{}r\PYGZhy{}\PYGZhy{}. \PYG{l+m}{1} z1234567 unsw \PYG{l+m}{2235} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 activate
\PYGZhy{}rw\PYGZhy{}r\PYGZhy{}\PYGZhy{}r\PYGZhy{}\PYGZhy{}. \PYG{l+m}{1} z1234567 unsw \PYG{l+m}{1291} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 activate.csh
\PYGZhy{}rw\PYGZhy{}r\PYGZhy{}\PYGZhy{}r\PYGZhy{}\PYGZhy{}. \PYG{l+m}{1} z1234567 unsw \PYG{l+m}{2443} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 activate.fish
\PYGZhy{}rwxr\PYGZhy{}xr\PYGZhy{}x. \PYG{l+m}{1} z1234567 unsw  \PYG{l+m}{266} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 easy\PYGZus{}install
\PYGZhy{}rwxr\PYGZhy{}xr\PYGZhy{}x. \PYG{l+m}{1} z1234567 unsw  \PYG{l+m}{266} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 easy\PYGZus{}install\PYGZhy{}3.7
\PYGZhy{}rwxr\PYGZhy{}xr\PYGZhy{}x. \PYG{l+m}{1} z1234567 unsw  \PYG{l+m}{248} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 pip
\PYGZhy{}rwxr\PYGZhy{}xr\PYGZhy{}x. \PYG{l+m}{1} z1234567 unsw  \PYG{l+m}{248} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 pip3
\PYGZhy{}rwxr\PYGZhy{}xr\PYGZhy{}x. \PYG{l+m}{1} z1234567 unsw  \PYG{l+m}{248} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 pip3.7
lrwxrwxrwx. \PYG{l+m}{1} z1234567 unsw    \PYG{l+m}{7} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 python \PYGZhy{}\PYGZgt{} python3
lrwxrwxrwx. \PYG{l+m}{1} z1234567 unsw   \PYG{l+m}{30} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 python3 \PYGZhy{}\PYGZgt{} /apps/python/3.7.4/bin/python3
\end{sphinxVerbatim}

In \sphinxcode{\sphinxupquote{lib}} we need to traverse a few more directories, but eventually we will see where the packages are installed. As you can see, \sphinxcode{\sphinxupquote{pip}} and \sphinxcode{\sphinxupquote{setuptools}} are already installed. These are the default:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{[}z1234567@katana2 \PYGZti{}\PYG{o}{]}\PYGZdl{} ls \PYGZhy{}l \PYGZti{}/.venvs/venv\PYGZhy{}tutorial\PYGZhy{}1/lib/python3.7/site\PYGZhy{}packages/
total \PYG{l+m}{16}
\PYGZhy{}rw\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{1} z1234567 unsw  \PYG{l+m}{126} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 easy\PYGZus{}install.py
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{5} z1234567 unsw   \PYG{l+m}{90} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 pip
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{2} z1234567 unsw \PYG{l+m}{4096} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 pip\PYGZhy{}19.0.3.dist\PYGZhy{}info
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{5} z1234567 unsw   \PYG{l+m}{89} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 pkg\PYGZus{}resources
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{2} z1234567 unsw   \PYG{l+m}{40} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 **pycache**
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{6} z1234567 unsw \PYG{l+m}{4096} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 setuptools
drwx\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}. \PYG{l+m}{2} z1234567 unsw \PYG{l+m}{4096} Mar \PYG{l+m}{23} \PYG{l+m}{11}:45 setuptools\PYGZhy{}40.8.0.dist\PYGZhy{}info
\end{sphinxVerbatim}


\section{Jupyter Notebooks}
\label{\detokenize{software/python-jupyter-notebooks:jupyter-notebooks}}\label{\detokenize{software/python-jupyter-notebooks::doc}}

\subsection{or, the ‘“it’s slightly frustrating, but can be done using the tools” way of running Juypter on Katana’}
\label{\detokenize{software/python-jupyter-notebooks:or-the-it-s-slightly-frustrating-but-can-be-done-using-the-tools-way-of-running-juypter-on-katana}}

\subsubsection{Background}
\label{\detokenize{software/python-jupyter-notebooks:background}}
Due to the nature of the Katana system, it’s not possible to serve content to the internet from Katana. Juypter notebooks are, essentially, python engines served via http. As a result, getting a notebook working requires a little more work than usual, but should get adequate results. This documentation is minimal, because it points to two other sets of documenation that have more information. WARNING: while it’s possible to run Jupyter Notebooks on Katana, it’s not an ideal system to run Jupyter on (at the moment). As a result, you may find that you experience is degraded \sphinxhyphen{} it’s highly dependant on network latency. We would recommend against it and will not be able to provide usability or performance support. We can continue to provide you with Python support, and Jupyter support.

We need to do a two main steps to prepare, and then each connection will require two steps to connect to your notebook.


\subsubsection{Preparation}
\label{\detokenize{software/python-jupyter-notebooks:preparation}}
These two steps are independant of each other \sphinxhyphen{} there is no need to do them in order.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
You will need to be able to connect to Katana via Remote Desktop. There are Instructions on how to do this in {\hyperref[\detokenize{using_katana/accessing_katana:graphical-session}]{\sphinxcrossref{\DUrole{std,std-ref}{Graphical sessions}}}}.

\item {} 
You will need to create a Python Virtual Environment ({\hyperref[\detokenize{software/python-virtualenvs:python-virtual-environments}]{\sphinxcrossref{\DUrole{std,std-ref}{Python Virtual Environments}}}}), activate it, and install Jupyter via the command \sphinxcode{\sphinxupquote{pip install jupyter}}

\end{enumerate}


\subsubsection{Reconnection}
\label{\detokenize{software/python-jupyter-notebooks:reconnection}}
Everytime you would like to use your Jupyter notebook, you will need to:
\begin{itemize}
\item {} 
Remote Desktop into Katana

\item {} 
open a terminal

\item {} 
start an interactive session \sphinxhyphen{} \sphinxcode{\sphinxupquote{qsub \sphinxhyphen{}I}} \sphinxhyphen{} and wait for it to start

\item {} 
in the interactive session, load any relevant modules (if applicable)

\item {} 
activate your virtual environment

\item {} 
grab the IP address of the node you are on: \sphinxcode{\sphinxupquote{hostname \sphinxhyphen{}I | awk '\{print \$1\}'}}

\item {} 
launch Jupyter Notebook like this: \sphinxcode{\sphinxupquote{jupyter\sphinxhyphen{}notebook \sphinxhyphen{}\sphinxhyphen{}ip=\$(hostname \sphinxhyphen{}I | awk '\{print \$1\}') \sphinxhyphen{}\sphinxhyphen{}no\sphinxhyphen{}browser}}

\item {} 
copy one of the first two options (the \sphinxcode{\sphinxupquote{file:///}} or \sphinxcode{\sphinxupquote{http://10.197.34.xxx:8888}}) into firefox in the remote desktop session

\end{itemize}

Caveat: if you get an error about a port being busy, launch Jupyter with this command, susbstituting XXXX with a large number:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
jupyter\PYGZhy{}notebook \PYGZhy{}\PYGZhy{}port\PYG{o}{=}XXXX
\end{sphinxVerbatim}


\subsubsection{IMPORTANT FINAL POINT}
\label{\detokenize{software/python-jupyter-notebooks:important-final-point}}
We will forcibly kill Jupyter notebooks we find running on katana1 or katana2 (collectively known as “the head nodes”) without warning or explanation beyond this paragraph. All jupyter notebooks must be started in an {\hyperref[\detokenize{using_katana/running_jobs:interactive-session}]{\sphinxcrossref{\DUrole{std,std-ref}{Interactive Jobs}}}} on Katana.


\section{R and RStudio}
\label{\detokenize{software/r:r-and-rstudio}}\label{\detokenize{software/r:r}}\label{\detokenize{software/r::doc}}
R is installed as a module. Each version has a number of libraries installed within it.

If you would like a new library installed, please email the \sphinxhref{mailto:ITServiceCentre@unsw.edu.au}{IT Service Centre} with Katana R Module installation in the subject line.

It is possible to use RStudio on Katana.


\section{SAS}
\label{\detokenize{software/sas:sas}}\label{\detokenize{software/sas::doc}}
The 64\sphinxhyphen{}bit version of SAS is available as a module.

By default SAS will store temporary files in \sphinxcode{\sphinxupquote{/tmp}} which can easily fill up leaving the node offline. In order to avoid this we have set the default to \sphinxcode{\sphinxupquote{\$TMPDIR}} to save temporary files in \sphinxcode{\sphinxupquote{/var/tmp}} on the Katana head node and local scratch on compute nodes. If you wish to save temporary files to a different location you can do that by using the \sphinxcode{\sphinxupquote{\sphinxhyphen{}work}} flag with your SAS command or adding this line to your \sphinxcode{\sphinxupquote{sasv9.cfg}} file:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZhy{}work /my/directory
\end{sphinxVerbatim}


\section{Stata}
\label{\detokenize{software/stata:stata}}\label{\detokenize{software/stata::doc}}
Stata is availt as a module.

When using Stata in a pbs batch script, the syntax is

\begin{sphinxVerbatim}[commandchars=\\\{\}]
stata \PYGZhy{}b \PYG{k}{do} StataClusterWorkshop.do
\end{sphinxVerbatim}

If you wish to load or install additional Stata modules or commands you should use findit command on your local computer to find the command that you are looking for. Then create a directory called \sphinxcode{\sphinxupquote{myadofiles}} in your home directory and copy the .ado (and possibly the .hlp) file into that directory. Now that the command is there it just remains to tell Stata to look in that directory which can be done by using the following Stata command.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
sysdir \PYG{n+nb}{set} PERSONAL \PYG{n+nv}{\PYGZdl{}HOME}/myadofiles
\end{sphinxVerbatim}


\section{TMUX}
\label{\detokenize{software/tmux:tmux}}\label{\detokenize{software/tmux::doc}}
\sphinxhref{https://github.com/tmux/tmux/wiki}{tmux} is available on Katana. It can be used to manage multiple sessions, including keeping then alive despite a terminal losing connectivity or being shutdown.

When you login to Katana using the terminal, it is a “live” session \sphinxhyphen{} if you close the terminal, the session will also close. If you shut your laptop or turn off the network, you will also kill the session.

This is fine, except when you have a long running program \sphinxhyphen{} say you are downloading a large data set \sphinxhyphen{} and you need to leave campus.

In these situations, you can use \sphinxcode{\sphinxupquote{tmux}} to create an \sphinxstylestrong{interruptible session}. \sphinxcode{\sphinxupquote{tmux}} has other powerful features \sphinxhyphen{} multiple sessions and split screens being two of many features.

To start tmux, type \sphinxcode{\sphinxupquote{tmux}} at the terminal. A new session will start and there will be a green information band at the bottom of the screen.

Anything you start in this session will keep running even if you are disconnected from that session regardless of the reason. Except when the server itself is rebooted. That \sphinxhyphen{} and I hope this is obvious \sphinxhyphen{} will kill all sessions.

If you do get detached, you can re\sphinxhyphen{}attach by logging into the same server and using the command \sphinxcode{\sphinxupquote{tmux a}}

tmux is similar to another program called \sphinxcode{\sphinxupquote{screen}} which is also available.


\chapter{Reference Data}
\label{\detokenize{reference_data:reference-data}}\label{\detokenize{reference_data:id1}}\label{\detokenize{reference_data::doc}}
We keep a number of reference data sets available on Katana at \sphinxcode{\sphinxupquote{/data/}} so that we don’t accidentally \sphinxhyphen{} for instance \sphinxhyphen{} end up with 150 copies of the Human Genome in user’s home directories.

As these are reference data, they don’t change often and we can update them as necessary.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Katana Data Sets}\label{\detokenize{reference_data:id2}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{3}{99}|\X{43}{99}|\X{43}{99}|\X{10}{99}|}
\hline
\sphinxstyletheadfamily 
Directory
&\sphinxstyletheadfamily 
Description
&\sphinxstyletheadfamily 
Update Schedule
&\sphinxstyletheadfamily 
URL
\\
\hline
annovar
&
Reference datasets that come with software installation.
&
Installed when software is installed.
&
annovar.openbioinformatics.org
\\
\hline
antismash
&
Reference files and commands for antismash version 4.2.0
&
Version specific database installed when software is installed
&
antismash.secondarymetabolites.org
\\
\hline
blast
&
NCBI nr, nt, refseq\_genomic and refseq datasets
&
Updated on release 6 times a year
&
www.ncbi.nlm.nih.gov/refseq
\\
\hline
blastv5
&
Version 5 of NCBI nr, nt, refseq\_genomic and refseq datasets.
&
Updated on release 6 times a year.
&
www.ncbi.nlm.nih.gov/refseq
\\
\hline
diamond
&
Diamond reference databases for versions 0.8.38, 0.9.10, 0.9.22 and 0.9.24. Database format periodically changes.
&
Updated when NCBI nr databases are updated.
&
ab.inf.uni\sphinxhyphen{}tuebingen.de/software/diamond
\\
\hline
gtdbtk
&&
Version specific database installed when software is installed.
&\\
\hline
hapcol
&
Reference datasets that come with software installation.
&
Installed when software is installed.
&
hapcol.algolab.eu
\\
\hline
hg19
&
Human reference genome hg19 (GRCh37).
&
Fixed reference. Never updated.
&
www.ncbi.nlm.nih.gov/grc
\\
\hline
interproscan
&
Reference datasets for InterProScan versions 5.20\sphinxhyphen{}59.0 and 5.35\sphinxhyphen{}74.0
&
Version specific database installed when software is installed.
&
www.ebi.ac.uk/interpro
\\
\hline
itasser
&
Rererence datasets for I\sphinxhyphen{}TASSER plus link to current nr database.
&
Version specific databases installed when software is installed plus link to nr database (see blast above).
&
zhanglab.ccmb.med.umich.edu/I\sphinxhyphen{}TASSER
\\
\hline
kaiju
&
Reference databases for all versions of Kaiju. Same databases for all versions.
&
Databases installed when software is installed.
&
kaiju.binf.ku.dk
\\
\hline
matam
&
Reference databases for all MATAM versions.
&
Version specific database installed when software is installed.
&
github.com/bonsai\sphinxhyphen{}team/matam
\\
\hline
megan
&
Reference databases for all MEGAN versions.
&
Version specific database installed when software is installed.
&
ab.inf.uni\sphinxhyphen{}tuebingen.de/software/megan6
\\
\hline
repeatmasker
&
Reference datasets for RepeatMasker version 4.0.7
&
Version specific database installed when software is installed.
&
www.repeatmasker.org
\\
\hline
trinotate
&
Reference databases for all versions of Kaiju. Same databases for all versions.
&
Databases installed when software is installed.
&
trinotate.github.io
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\chapter{Frequently Asked Questions}
\label{\detokenize{faq:frequently-asked-questions}}\label{\detokenize{faq::doc}}

\section{General FAQ}
\label{\detokenize{faq:general-faq}}

\subsection{Where is the best place to store my code?}
\label{\detokenize{faq:where-is-the-best-place-to-store-my-code}}
The best place to store source code is to use version control and store it in a repository.  This means that you will be able to keep every version of your code and revert to an earlier version if you require. \sphinxhref{https://research.unsw.edu.au/github}{UNSW has a central github account}, but we encourage you to create your own.


\subsection{I just got some money from a grant. What can I spend it on?}
\label{\detokenize{faq:i-just-got-some-money-from-a-grant-what-can-i-spend-it-on}}
There are a number of different options for using research funding to improve your ability to run computationally intensive programs. The best starting point is to {\hyperref[\detokenize{help_and_support:contact-us}]{\sphinxcrossref{\DUrole{std,std-ref}{Contact the Research Technology Services team}}}} to figure out the different options.


\subsection{Can I access Katana from outside UNSW?}
\label{\detokenize{faq:can-i-access-katana-from-outside-unsw}}
Yes, if you have an account then you can connect to Katana from both inside and outside UNSW. Some services \sphinxhyphen{} like remote desktops \sphinxhyphen{} will not be as responsive as inside the UNSW network.


\section{Scheduler FAQ}
\label{\detokenize{faq:scheduler-faq}}\label{\detokenize{faq:katana-compute-faq}}

\subsection{Does Katana run a 32 bit or a 64 bit operating system?}
\label{\detokenize{faq:does-katana-run-a-32-bit-or-a-64-bit-operating-system}}
Katana {\hyperref[\detokenize{glossary:term-Compute-Nodes}]{\sphinxtermref{\DUrole{xref,std,std-term}{Compute Nodes}}}} run a 64 bit version of the CentOS distribution of Linux. Currently version 7.8. The {\hyperref[\detokenize{glossary:term-Head-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Head Node}}}} runs RedHat 7.8.


\subsection{How much memory is available per core and/or per node?}
\label{\detokenize{faq:how-much-memory-is-available-per-core-and-or-per-node}}
The amount of memory available varies across the cluster. To determine how much memory each node has available use the ‘pbsnodes’ command. Roughly, you can safely use 4GB per core requested. You can request more memory but it may delay time spent in the queue.


\subsection{How much memory can I use on the login node for compiling software?}
\label{\detokenize{faq:how-much-memory-can-i-use-on-the-login-node-for-compiling-software}}
The login nodes have a total of 24GB of memory each. Each individual user is limited to 4GB and should only be used to compile software. If you need more, do it in an {\hyperref[\detokenize{glossary:term-Interactive-Job}]{\sphinxtermref{\DUrole{xref,std,std-term}{Interactive Job}}}}.


\subsection{Why isn’t my job making it onto a node even though it says that some nodes are free?}
\label{\detokenize{faq:why-isn-t-my-job-making-it-onto-a-node-even-though-it-says-that-some-nodes-are-free}}
There are three main reasons you will see this behavior. The first of them is specific to Katana and the other two apply to any cluster.

Firstly, the compute nodes in Katana belong to various schools and research groups across UNSW. Any job with an expected run\sphinxhyphen{}time longer than 12 hours can only run on a compute node that is somehow associated with the owner of the job. For example, if you are in the CCRC you are entitled to run 12+ hour jobs on the General nodes and the nodes jointly purchased by CCRC. However, you cannot run 12+ hour jobs on the nodes purchased by Astrobiology, Statistics, TARS, CEPAR or Physics. So you may see idle nodes, but you may not be entitled to run a 12+ hour job on them.

Secondly, the idle nodes may not have sufficient resources for your job. For example, if you have asked for 100GB memory but there are only 50GB free on the “idle node”.

Thirdly, there may be distributed memory jobs ahead of your job in the queue which have reservations on the idle nodes, and they are just waiting for all of their requested resources to become available. In this case, your job can only use the reserved nodes if your job can finish before the nodes are required by the distributed memory job. For example, if a job has been waiting a week (yes, it happens) for \sphinxcode{\sphinxupquote{walltime=200,cpu=88,mem=600GB}} (very long, two whole nodes), then those resources will need to be made available at some point. This is an excellent example of why breaking your jobs up into smaller parts is good HPC practice.


\subsection{How many jobs can I submit at the one time?}
\label{\detokenize{faq:how-many-jobs-can-i-submit-at-the-one-time}}
Technically you can submit as many jobs as you wish. The queuing system run by the scheduler is designed to prevent a single user flooding the system \sphinxhyphen{} each job will reduce the priority of your next jobs. In this way the infrequent users get a responsive system without impacting the regular users too much.

Whilst there is not a technical limit to the number of jobs you can submit, submitting more that 2,000 jobs at the one time can place an unacceptable load on the job scheduler and your jobs may be deleted without warning. This is an editorial decision by management.


\subsection{What is the maximum number of CPUs I can use in parallel?}
\label{\detokenize{faq:what-is-the-maximum-number-of-cpus-i-can-use-in-parallel}}
As many as your account and queue will allow you. But there are trade\sphinxhyphen{}offs \sphinxhyphen{} if you ask for 150 CPUs (\textasciitilde{}5 full servers) you might be waiting more than a couple of months for your job to run.

If you are regularly wanting to run large parallel jobs (16+ cores per job) on Katana you should consider speaking to {\hyperref[\detokenize{help_and_support:help-and-support}]{\sphinxcrossref{\DUrole{std,std-ref}{Help and Support}}}} so that they are aware of your jobs. They may be able to provide you additional assistance on resource usage for parallel jobs.


\subsection{Why does my SSH connection periodically dsconnect?}
\label{\detokenize{faq:why-does-my-ssh-connection-periodically-dsconnect}}
With all networks there is a limit to how long a connection between two computers will stay open if no data is travelling between them. Look to set your ServerAliveInterval or Keep Alive interval to 60 in your secure shell software (putty, ssh).


\subsection{Can I change the job script after it has been submitted?}
\label{\detokenize{faq:can-i-change-the-job-script-after-it-has-been-submitted}}
Yes you increase the resource values for jobs that are still queued, but even then you are constrained by the limits of the particular queue that you are submitting to. Once it has been assigned to a node the intricacies of the scheduling policy means that it becomes impossible for anyone including the administrator to make any further changes


\subsection{Where does Standard Output (STDOUT) go when a job is run?}
\label{\detokenize{faq:where-does-standard-output-stdout-go-when-a-job-is-run}}
By default Standard Output is redirected to storage on the node and then transferred when the job is completed. If you are generating data you should redirect \sphinxcode{\sphinxupquote{STDOUT}} to a different location. The best location depends on the characteristics of your job but in general all \sphinxcode{\sphinxupquote{STDOUT}} should be redirected to local scratch.


\subsection{How do I figure out what the resource requirements of my job are?}
\label{\detokenize{faq:how-do-i-figure-out-what-the-resource-requirements-of-my-job-are}}
The best way to determine the resource requirements of your job is to be generous with the resource requirements on the first run and then refine the requirements based on what the job actually used. If you put the following information in your job script you will receive an email when the job finishes which will include a summary of the resources used.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}M z1234567@unsw.edu.au}
\PYG{c+c1}{\PYGZsh{}PBS \PYGZhy{}m ae}
\end{sphinxVerbatim}


\subsection{Can I cause problems to other users if I request too many resources or make a mistake with my job script?}
\label{\detokenize{faq:can-i-cause-problems-to-other-users-if-i-request-too-many-resources-or-make-a-mistake-with-my-job-script}}
Yes, but it’s extremely unlikely. We used to say no, but that’s not strictly true. The reality is that if something breaks it’s usually your job hitting the odd corner case we didn’t account for. It doesn’t happen often.


\subsection{Will a job script from another cluster work on cluster X?}
\label{\detokenize{faq:will-a-job-script-from-another-cluster-work-on-cluster-x}}
It depends on a number of factors including the sceduling software. Some aspects are fairly common across different clusters (e.g. walltime) others are not. You should look at the cluster specific information to see what queuing system is being used on that cluster and what commands you will need to change. You wont find a cluster that doesn’t have knowledgable support that can help you migrate.


\subsection{How can I see exactly what resources (I/O, CPU, memory and scratch) my job is currently using?}
\label{\detokenize{faq:how-can-i-see-exactly-what-resources-i-o-cpu-memory-and-scratch-my-job-is-currently-using}}
From \sphinxstyleemphasis{outside} the job, you can run \sphinxcode{\sphinxupquote{qstat \sphinxhyphen{}f <jobid>}}.

If, for instance, you wanted to measure different steps of your process, then inside your jobscript you can put \sphinxcode{\sphinxupquote{qstat \sphinxhyphen{}f \$PBS\_JOBID}}

For fine grain detail, you may need to get access to the worker node that the job is running on:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
qstat \PYGZhy{}nru \PYG{n+nv}{\PYGZdl{}USER}
\end{sphinxVerbatim}

then you can see a list of your running jobs and where they are running. You can then use ssh to log on to the individual nodes and run \sphinxcode{\sphinxupquote{top}} or \sphinxcode{\sphinxupquote{htop}} to see the load on the node including memory usage for each of the processes on the node.


\subsection{How do I request the installation or upgrade of a piece of software ?}
\label{\detokenize{faq:how-do-i-request-the-installation-or-upgrade-of-a-piece-of-software}}
If you wish to have a new piece of software installed or software that is already installed upgraded please send an email to the \sphinxhref{mailto:ITServiceCentre@unsw.edu.au}{IT Service Centre} from your UNSW email account with details of what software change you require and the cluster that you would like it changed on.


\subsection{Why is my job stuck in the queue whilst other jobs run?}
\label{\detokenize{faq:why-is-my-job-stuck-in-the-queue-whilst-other-jobs-run}}
The queues are not set up to be first\sphinxhyphen{}in\sphinxhyphen{}first\sphinxhyphen{}out. In fact all of the queued jobs sit in one big pool of jobs that are ready to run. The scheduler assigns priorities to jobs in the pool and the job with the highest priority is the next one to run. The length of time spent waiting in the pool is just one of several factors that are used to determine priority.

For example, people who have used the cluster heavily over the last two weeks receive a negative contribution to their jobs’ priority, whereas a light user will receive a positive contribution. You can see this in action with the diagnose \sphinxhyphen{}p and diagnose \sphinxhyphen{}f commands.


\subsection{You mentioned waiting time as a factor, what else affects the job priority?}
\label{\detokenize{faq:you-mentioned-waiting-time-as-a-factor-what-else-affects-the-job-priority}}
The following three factors combine to generate the job priority.
\begin{itemize}
\item {} 
How many resources (cpu and memory) have you and your group consumed in the last 14 days? Your personal consumption is weighted more highly than your group’s consumption. Heavy recent usage contributes a negative priority. Light recent usage contributes a positive priority.

\item {} 
How many resources does the job require? Always a positive contribution to priority, but increases linearly with the amount of cpu and memory requested, i.e. we like big jobs.

\item {} 
How long has the job been waiting in the queue? Always a positive contribution to priority, but increases linearly with the amount of time your job has been waiting in the queue. Note that throttling policies will prevent some jobs from being considered for scheduling, in which case their clock does not start ticking until that throttling constraint is lifted.

\end{itemize}


\subsection{What happens if my job uses more memory than I requested?}
\label{\detokenize{faq:what-happens-if-my-job-uses-more-memory-than-i-requested}}
The job will be killed by the scheduler. You will get a message to that effect if you have any types of notification enabled (logs, emails).


\subsection{What happens if my job is still running when it reaches the end of the time that I have requested?}
\label{\detokenize{faq:what-happens-if-my-job-is-still-running-when-it-reaches-the-end-of-the-time-that-i-have-requested}}
When your job hits it’s {\hyperref[\detokenize{glossary:term-Walltime}]{\sphinxtermref{\DUrole{xref,std,std-term}{Walltime}}}} it is automatically terminated by the scheduler.


\subsection{200 hours is not long enough! What can I do?}
\label{\detokenize{faq:hours-is-not-long-enough-what-can-i-do}}
If you find that your jobs take longer than the maximum WALL time then there are several different options to change your code so that it fits inside the parameters.
\begin{itemize}
\item {} 
Can your job be split into several independent jobs?

\item {} 
Can you export the results to a file which can then be used as input for the next time the job is run?

\end{itemize}

You may want to also look to see if there is anything that you can do to make your code run better like making better use of local scratch if your code is I/O intensive.


\subsection{Do sub\sphinxhyphen{}jobs within an array job run in parallel, or do they queue up serially?}
\label{\detokenize{faq:do-sub-jobs-within-an-array-job-run-in-parallel-or-do-they-queue-up-serially}}
Submitting an array job with 100 sub\sphinxhyphen{}jobs is equivalent to submitting 100 individual jobs. So if sufficient resources are available then all 100 sub\sphinxhyphen{}jobs could run in parallel. Otherwise some sub\sphinxhyphen{}jobs will run and other sub\sphinxhyphen{}jobs must wait in the queue for resources to become available.

The ‘\%’ option in the array request offers the ability to self impose a limit on the number of concurrently running sub\sphinxhyphen{}jobs. Also, if you need to impose an order on when the jobs are run then the ‘depend’ attribute can help.


\subsection{In a pbs file does the MEM requested refer to each node or the total memory on all nodes being used (if I am using more than 1 node?}
\label{\detokenize{faq:in-a-pbs-file-does-the-mem-requested-refer-to-each-node-or-the-total-memory-on-all-nodes-being-used-if-i-am-using-more-than-1-node}}
MEM refers to the amount of memory per node.


\section{Storage FAQ}
\label{\detokenize{faq:storage-faq}}\label{\detokenize{faq:id1}}

\subsection{What storage is available to me?}
\label{\detokenize{faq:what-storage-is-available-to-me}}
Katana provides three different storage areas, cluster home drives, local scratch and global scratch. The storage page has additional information on the differences and advantages of each of the different types of storage. You may also want to consider storing your code using a version control service like GitHub. This means that you will be able to keep every version of your code and revert to an earlier version if you require.


\subsection{Which storage is fastest?}
\label{\detokenize{faq:which-storage-is-fastest}}
In order of performance the best storage to use is local scratch, global scratch and cluster home drive.


\subsection{Is any of the cluster based storage backed up?}
\label{\detokenize{faq:is-any-of-the-cluster-based-storage-backed-up}}
The only cluster based storage that gets backed up is the cluster home drives. All other storage including local and global scratch is not backed up.


\subsection{How do I actually use local scratch?}
\label{\detokenize{faq:how-do-i-actually-use-local-scratch}}
The easiest way of making use of local scratch is to use scripts to copy files to the node at the start of your job and from the node when your job finishes. You should also use local scratch for your working directory and temporary files.


\subsection{Why am I having trouble creating a symbolic link?}
\label{\detokenize{faq:why-am-i-having-trouble-creating-a-symbolic-link}}
Not all filesystems support symbolic links. The most common examples are some Windows network shares. On Katana this includes Windows network shares such as hdrive. The target of the symbolic link can be within such a filesystem, but the link itself must be on a filesystem that supports symbolic links, e.g. the rest of your home directory or your scratch directory.


\subsection{What storage is available on compute nodes?}
\label{\detokenize{faq:what-storage-is-available-on-compute-nodes}}
As well as local scratch, global scratch and your cluster home drive are accessible on the compute nodes.


\subsection{What is the best way to transfer a large amount of data onto a cluster?}
\label{\detokenize{faq:what-is-the-best-way-to-transfer-a-large-amount-of-data-onto-a-cluster}}
Use \sphinxcode{\sphinxupquote{rsync}} to copy data to the KDM server. More information is above.


\subsection{Is there any way of connecting my own file storage to one of the clusters?}
\label{\detokenize{faq:is-there-any-way-of-connecting-my-own-file-storage-to-one-of-the-clusters}}
Whilst it is not possible to connect individual drives to any of the clusters, some units and research groups have purchased large capacity storage units which are co\sphinxhyphen{}located with the clusters. This storage is then available on the cluster nodes. For more information please contact the Research Technology Service Team by placing a request with the \sphinxhref{mailto:ITServiceCentre@unsw.edu.au}{IT Service Centre}.


\subsection{Can I specify how much file storage I want on local scratch?}
\label{\detokenize{faq:can-i-specify-how-much-file-storage-i-want-on-local-scratch}}
If you want to specify the minimum amount of space on the drive before your job will be assigned to a node then you can use the file option in your job script. Unfortunately setting up more complicated file requirements is currently problematic.


\subsection{Can I run a program directly from scratch or my home drive after logging in to the cluster rather submitting a job?}
\label{\detokenize{faq:can-i-run-a-program-directly-from-scratch-or-my-home-drive-after-logging-in-to-the-cluster-rather-submitting-a-job}}
As the file server does not have any computational resources you would be running the job from the head node on the cluster. If you need to enter information when running your job then you should start an interactive job.


\section{Expanding Katana}
\label{\detokenize{faq:expanding-katana}}
Katana has significant potential for further expansion. It offers a simple and cost\sphinxhyphen{}effective way for research groups to invest in a powerful computing facility and take advantage of the economies that come with joining a system with existing infrastructure. A sophisticated job scheduler ensures that users always receive a fair share of the compute resources that is at least commensurate with their research group’s investment in the cluster. For more information please contact us.


\section{Acknowledging Katana}
\label{\detokenize{faq:acknowledging-katana}}
If you use Katana for calculations that result in a publication then you should add the following text to your work.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{This} \PYG{n}{research} \PYG{n}{includes} \PYG{n}{computations} \PYG{n}{using} \PYG{n}{the} \PYG{n}{computational} \PYG{n}{cluster} \PYG{n}{Katana} \PYG{n}{supported} \PYG{n}{by} \PYG{n}{Research} \PYG{n}{Technology} \PYG{n}{Services} \PYG{n}{at} \PYG{n}{UNSW} \PYG{n}{Sydney}\PYG{o}{.}
\end{sphinxVerbatim}

If you are using nodes that have been purchased using an external funding source you should also acknowledge the source of those funds.

For information about \sphinxhref{https://www.arc.gov.au/acknowledging-arc}{acknowledging ARC funding}

Your School or Research Group may also have policies for compute nodes that they have purchased.


\subsection{Facilities external to UNSW}
\label{\detokenize{faq:facilities-external-to-unsw}}
If you are using facilities at \sphinxhref{https://intersect.org.au/attribution}{Intersect} or \sphinxhref{http://nci.org.au/users/nci-terms-and-conditions-access}{NCI} in addition to Katana they may also require some form of acknowledgement.


\chapter{Glossary}
\label{\detokenize{glossary:glossary}}\label{\detokenize{glossary::doc}}\begin{description}
\item[{Active Job\index{Active Job@\spxentry{Active Job}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Active-Job}}}] \leavevmode
Active jobs are jobs that have been assigned to a compute node and are currently running. These can be seen by running \sphinxcode{\sphinxupquote{qstat}} and looking for an A in the second last column. See {\hyperref[\detokenize{using_katana/running_jobs:more-info-from-pbs}]{\sphinxcrossref{\DUrole{std,std-ref}{Show all jobs on the system}}}}

\item[{Array Job\index{Array Job@\spxentry{Array Job}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Array-Job}}}] \leavevmode
If you want to run the same job multiple times with slight differences (filenames, data source, etc), then you can create an array job which will submit multiple jobs for you from the one job script.

\item[{Batch Job\index{Batch Job@\spxentry{Batch Job}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Batch-Job}}}] \leavevmode
A batch job is a job on a cluster that runs without any further input once it has been submitted. Almost all jobs on the cluster are batch jobs. All jobs are either batch jobs or {\hyperref[\detokenize{glossary:term-Interactive-Job}]{\sphinxtermref{\DUrole{xref,std,std-term}{Interactive Job}}}}.

\item[{Blade\index{Blade@\spxentry{Blade}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Blade}}}] \leavevmode
Some of the compute nodes Katana are called blade servers which allow a higher density of servers in the same space. Each blade consists of multiple CPUs with 6 or more cores.

\item[{Cluster\index{Cluster@\spxentry{Cluster}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Cluster}}}] \leavevmode
A computer cluster is a set of connected computers that work together so that, in many respects, they can be viewed as a single system. Using a cluster is referred to as High Performance Computing or HPC. Most will have a {\hyperref[\detokenize{glossary:term-Management-Plane}]{\sphinxtermref{\DUrole{xref,std,std-term}{Management Plane}}}} and several {\hyperref[\detokenize{glossary:term-Compute-Nodes}]{\sphinxtermref{\DUrole{xref,std,std-term}{Compute Nodes}}}}.

\item[{Compute Nodes\index{Compute Nodes@\spxentry{Compute Nodes}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Compute-Nodes}}}] \leavevmode
The compute nodes are where the compute jobs run. Users submit jobs from the {\hyperref[\detokenize{glossary:term-Login-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Login Node}}}} and the {\hyperref[\detokenize{glossary:term-Job-Scheduler}]{\sphinxtermref{\DUrole{xref,std,std-term}{Job Scheduler}}}} on the {\hyperref[\detokenize{glossary:term-Head-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Head Node}}}} will assign the job to one or more compute nodes.

\item[{CPU Core\index{CPU Core@\spxentry{CPU Core}|spxpagem}\phantomsection\label{\detokenize{glossary:term-CPU-Core}}}] \leavevmode
Each node in the cluster has one or more CPUs each of which has 6 or more cores. Each core is able to run one job at a time so a node with 12 cores could have 12 jobs running in parallel.

\item[{Data Transfer Node\index{Data Transfer Node@\spxentry{Data Transfer Node}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Data-Transfer-Node}}}] \leavevmode
The Data Transfer Node, also known as the {\hyperref[\detokenize{storage/kdm:katana-data-mover}]{\sphinxcrossref{\DUrole{std,std-ref}{Katana Data Mover}}}} (KDM), is a server that is used for transferring files to, from, and within the cluster. Due to the nature of moving data around, it uses a significant amount of memory and network bandwidth. This server is used to take that load off the {\hyperref[\detokenize{glossary:term-Login-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Login Node}}}}.

\item[{Environment Variable\index{Environment Variable@\spxentry{Environment Variable}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Environment-Variable}}}] \leavevmode
Environment variables are variables that are set in Linux to tell applications where to find programs and set program options. They will start with a \$ symbol. For example, all users can reference \sphinxcode{\sphinxupquote{\$TMPDIR}} in their {\hyperref[\detokenize{glossary:term-Job-Script}]{\sphinxtermref{\DUrole{xref,std,std-term}{Job Script}}}} in order to use {\hyperref[\detokenize{glossary:term-Local-Scratch}]{\sphinxtermref{\DUrole{xref,std,std-term}{Local Scratch}}}}

\item[{Global Scratch\index{Global Scratch@\spxentry{Global Scratch}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Global-Scratch}}}] \leavevmode
Global scratch is a large data store for data that isn’t backed up. It differs from local scratch in that it is available from every node including the {\hyperref[\detokenize{glossary:term-Head-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Head Node}}}}. If you have data files or working directories this is where you should put them.

\item[{Head Node\index{Head Node@\spxentry{Head Node}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Head-Node}}}] \leavevmode
The head node of the {\hyperref[\detokenize{glossary:term-Cluster}]{\sphinxtermref{\DUrole{xref,std,std-term}{Cluster}}}} is the computer that manages job and resource management. This is where the {\hyperref[\detokenize{glossary:term-Job-Scheduler}]{\sphinxtermref{\DUrole{xref,std,std-term}{Job Scheduler}}}} and {\hyperref[\detokenize{glossary:term-Resource-Manager}]{\sphinxtermref{\DUrole{xref,std,std-term}{Resource Manager}}}} run. It is kept separate from the {\hyperref[\detokenize{glossary:term-Login-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Login Node}}}} so that production doesn’t stop if someone accidentally breaks the {\hyperref[\detokenize{glossary:term-Login-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Login Node}}}}.

\item[{Held Jobs\index{Held Jobs@\spxentry{Held Jobs}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Held-Jobs}}}] \leavevmode
Held jobs are jobs that cannot currently run. They are put into that state by either the server or the system administrator. Jobs stay held until released by a systems administrator, at which point they become {\hyperref[\detokenize{glossary:term-Queued-Jobs}]{\sphinxtermref{\DUrole{xref,std,std-term}{Queued Jobs}}}}. These can be seen by running \sphinxcode{\sphinxupquote{qstat}} and looking for an H in the second last column. See {\hyperref[\detokenize{using_katana/running_jobs:more-info-from-pbs}]{\sphinxcrossref{\DUrole{std,std-ref}{Show all jobs on the system}}}}

\item[{Interactive Job\index{Interactive Job@\spxentry{Interactive Job}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Interactive-Job}}}] \leavevmode
An interactive job is a way of testing your program and data on a cluster without negatively impacting the {\hyperref[\detokenize{glossary:term-Login-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Login Node}}}}. Once a request has been submitted and accepted for an interactive job, the user will no longer be on the relatively small login nodes, and will have access to the resources requested on the {\hyperref[\detokenize{glossary:term-Compute-Nodes}]{\sphinxtermref{\DUrole{xref,std,std-term}{Compute Nodes}}}}. In other words, your terminal session will move from a small (virtual) computer you share with many people to a large computer you share with very few people. All jobs are either a {\hyperref[\detokenize{glossary:term-Batch-Job}]{\sphinxtermref{\DUrole{xref,std,std-term}{Batch Job}}}} or an interactive job. Instructions on using {\hyperref[\detokenize{using_katana/running_jobs:interactive-job}]{\sphinxcrossref{\DUrole{std,std-ref}{Interactive Jobs}}}}

\item[{Job Scheduler\index{Job Scheduler@\spxentry{Job Scheduler}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Job-Scheduler}}}] \leavevmode
The job scheduler monitors the jobs currenty running on the cluster and assigns {\hyperref[\detokenize{glossary:term-Queued-Jobs}]{\sphinxtermref{\DUrole{xref,std,std-term}{Queued Jobs}}}} to {\hyperref[\detokenize{glossary:term-Compute-Nodes}]{\sphinxtermref{\DUrole{xref,std,std-term}{Compute Nodes}}}} based on recent cluster useage, job resource requirements and nodes available to the research group of the submitter. In summary the job scheduler determines when and where a job should run. The job scheduler that we use is called PBSPro.

\item[{Job Script\index{Job Script@\spxentry{Job Script}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Job-Script}}}] \leavevmode
A job script is a file containing all of the information needed to run a {\hyperref[\detokenize{glossary:term-Batch-Job}]{\sphinxtermref{\DUrole{xref,std,std-term}{Batch Job}}}} including the resource requirements and the actual commands to run the job.

\item[{Local Scratch\index{Local Scratch@\spxentry{Local Scratch}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Local-Scratch}}}] \leavevmode
Local scratch refers to the storage available internally on each compute node. Of all the different scratch directories this storage has the best performance however you will need to move your data into local scratch as part of your job script. You can use local scratch with the {\hyperref[\detokenize{glossary:term-Environment-Variable}]{\sphinxtermref{\DUrole{xref,std,std-term}{Environment Variable}}}} \sphinxcode{\sphinxupquote{\$TMPDIR}}

\item[{Login Node\index{Login Node@\spxentry{Login Node}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Login-Node}}}] \leavevmode
The login nodes of the cluster is the computer that you log in to when you connect to the cluster. This node is used to compile software and submit jobs.

\item[{Module\index{Module@\spxentry{Module}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Module}}}] \leavevmode
The module command is a means of providing access to different versions of software without risking version conflicts across multiple users.

\item[{Management Plane\index{Management Plane@\spxentry{Management Plane}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Management-Plane}}}] \leavevmode
The Management Plane is the set of servers that sit above or adjacent to the {\hyperref[\detokenize{glossary:term-Compute-Nodes}]{\sphinxtermref{\DUrole{xref,std,std-term}{Compute Nodes}}}}. These servers are used to manage the system, manage the storage, or manage the network. User’s have access to the {\hyperref[\detokenize{glossary:term-Login-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Login Node}}}} and {\hyperref[\detokenize{glossary:term-Data-Transfer-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Data Transfer Node}}}}. Other servers include the {\hyperref[\detokenize{glossary:term-Head-Node}]{\sphinxtermref{\DUrole{xref,std,std-term}{Head Node}}}}.

\item[{MPI\index{MPI@\spxentry{MPI}|spxpagem}\phantomsection\label{\detokenize{glossary:term-MPI}}}] \leavevmode
Message Passing Infrastructure (MPI) is a technology for running a {\hyperref[\detokenize{glossary:term-Batch-Job}]{\sphinxtermref{\DUrole{xref,std,std-term}{Batch Job}}}} on more than one {\hyperref[\detokenize{glossary:term-Compute-Nodes}]{\sphinxtermref{\DUrole{xref,std,std-term}{Compute Nodes}}}}. Designed for situations where parts of the job can run on independent nodes with the results being transferred to other nodes for the next part of the job to be run.

\item[{Network Drive\index{Network Drive@\spxentry{Network Drive}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Network-Drive}}}] \leavevmode
A network drive is a drive that is independant from the cluster.

\item[{Queue\index{Queue@\spxentry{Queue}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Queue}}}] \leavevmode
All submitted jobs are put into a queue. Each queue has a collection of resources available to it. As those resources become available, new jobs will be assigned to those resources. Job prioritisation is done by the scheduler and depends on a number of factors including length of wait time and total resource use by user over the previous month.

\item[{Queued Jobs\index{Queued Jobs@\spxentry{Queued Jobs}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Queued-Jobs}}}] \leavevmode
Queued jobs are eligible to run but are waiting for a {\hyperref[\detokenize{glossary:term-Compute-Nodes}]{\sphinxtermref{\DUrole{xref,std,std-term}{Compute Nodes}}}} that matches their requirements to become available. Which idle job will be assigned to a compute node next depends on the {\hyperref[\detokenize{glossary:term-Job-Scheduler}]{\sphinxtermref{\DUrole{xref,std,std-term}{Job Scheduler}}}}. These can be seen by running \sphinxcode{\sphinxupquote{qstat}} and looking for a Q in the second last column. See {\hyperref[\detokenize{using_katana/running_jobs:more-info-from-pbs}]{\sphinxcrossref{\DUrole{std,std-ref}{Show all jobs on the system}}}}

\item[{Resource Manager\index{Resource Manager@\spxentry{Resource Manager}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Resource-Manager}}}] \leavevmode
A resource manager works with the {\hyperref[\detokenize{glossary:term-Job-Scheduler}]{\sphinxtermref{\DUrole{xref,std,std-term}{Job Scheduler}}}} to manage running jobs on a cluster. Amongst other tasks it receives and parses job submissions, starts jobs on {\hyperref[\detokenize{glossary:term-Compute-Nodes}]{\sphinxtermref{\DUrole{xref,std,std-term}{Compute Nodes}}}}, monitors jobs, kills jobs, and manages how many {\hyperref[\detokenize{glossary:term-CPU-Core}]{\sphinxtermref{\DUrole{xref,std,std-term}{CPU Core}}}} are available on each {\hyperref[\detokenize{glossary:term-Compute-Nodes}]{\sphinxtermref{\DUrole{xref,std,std-term}{Compute Nodes}}}}

\item[{Scratch Space\index{Scratch Space@\spxentry{Scratch Space}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Scratch-Space}}}] \leavevmode
Scratch space is a non backed up storage area where users can store transient data. It should not be used for job code as it is not backed up.

\item[{Walltime\index{Walltime@\spxentry{Walltime}|spxpagem}\phantomsection\label{\detokenize{glossary:term-Walltime}}}] \leavevmode
In HPC, walltime is the amount of time that you will be allocated when your job runs. If your jobs runs longer than the walltime, it will be killed by the {\hyperref[\detokenize{glossary:term-Job-Scheduler}]{\sphinxtermref{\DUrole{xref,std,std-term}{Job Scheduler}}}}. It is used by the scheduler for helping allocate resources onto servers. On \sphinxstylestrong{Katana} it is also used to determine which {\hyperref[\detokenize{glossary:term-Queue}]{\sphinxtermref{\DUrole{xref,std,std-term}{Queue}}}} your job will end up in. The shorter the walltime, the more opportunity your job has to run which in turn means that it will start sooner. In short \sphinxhyphen{} it’s harder to find 100 hours of space than it is to find 12 hours of space.

\end{description}


\chapter{News}
\label{\detokenize{index:news}}
21/04/2020 \sphinxhyphen{} Jupyter has been installed on Katana as part of versions 3.7.3, 3.7.4 and the new 3.8.2 python modules.



\renewcommand{\indexname}{Index}
\printindex
\end{document}